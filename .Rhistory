getOption("na.action")
fit1 <- glm(y~.,family = binomial,data = dffit[complete.cases(dffit),])
summary(fit1)
deviance(fit1)
deviance(fit1) + 2(19)
deviance(fit1) + 2*19
deviance(fit1) + 2*18
1-pchisq(fit1$null.deviance - fit1$deviance, 1)
1-pchisq(fit1$null.deviance - fit1$deviance, 17)
anova(fit1,test = "Chisq")
1-pchisq(27.59, 17)
plot(fit1)
x.test <- test.models[ ,c(PotentialPred[-7],colnames(training.models) [grep("JOB_", colnames(training.models))])]
predictedClass <- ifelse(predict.glm(fit1,newdata = x.test, type = 'response') > 0.5, 1,0)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
rocCurve.fit1 <- roc(response = test.y, predictor = predictedClass)
plot(rocCurve.fit1, legacy.axes = T)
summary(fit1)
pROC::auc(rocCurve.fit1)
PotentialPred <- rownames(tr.boosted$importance)[order(tr.boosted$importance,decreasing = T)][1:11]
trainRows.models <- caret::createDataPartition(df.rev.cleaned$TARGET_FLAG2,p = 0.8, list = F)
training.models <- df.rev.cleaned[trainRows.models,]
test.models <- df.rev.cleaned[-trainRows.models,]
y <- ifelse(training.models$TARGET_FLAG2 == "No",0,1)
x <- as.matrix(training.models[ ,c(PotentialPred[-7],colnames(training.models) [grep("JOB_", colnames(training.models))])])
dffit <- data.frame(y,x)
fit1 <- glm(y~.,family = binomial,data = dffit[complete.cases(dffit),])
summary(fit1)
x.test <- test.models[ ,c(PotentialPred[-7],colnames(training.models) [grep("JOB_", colnames(training.models))])]
predictedClass <- ifelse(predict.glm(fit1,newdata = x.test, type = 'response') > 0.5, 1,0)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
rocCurve.fit1 <- roc(response = test.y, predictor = predictedClass)
plot(rocCurve.fit1, legacy.axes = T)
pROC::auc(rocCurve.fit1)
PotentialPred[-7]
summary(training)
PotentialPred <- rownames(tr.boosted$importance)[order(tr.boosted$importance,decreasing = T)][1:12]
#df.rev.imputed <- VIM::kNN(df.rev.cleaned)
#
trainRows.models <- caret::createDataPartition(df.rev.cleaned$TARGET_FLAG2,p = 0.8, list = F)
training.models <- df.rev.cleaned[trainRows.models,]
test.models <- df.rev.cleaned[-trainRows.models,]
y <- ifelse(training.models$TARGET_FLAG2 == "No",0,1)
x <- as.matrix(training.models[ ,c(PotentialPred[-7],colnames(training.models) [grep("JOB_", colnames(training.models))])])
dffit <- data.frame(y,x)
fit1 <- glm(y~.,family = binomial,data = dffit[complete.cases(dffit),])
summary(fit1)
x.test <- test.models[ ,c(PotentialPred[-7],colnames(training.models) [grep("JOB_", colnames(training.models))])]
predictedClass <- ifelse(predict.glm(fit1,newdata = x.test, type = 'response') > 0.5, 1,0)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
rocCurve.fit1 <- roc(response = test.y, predictor = predictedClass)
plot(rocCurve.fit1, legacy.axes = T)
pROC::auc(rocCurve.fit1)
pROC::auc(rocCurve.fit1)
summary(fit1)
predictedClass <- ifelse(predict.glm(fit1,newdata = x.test, type = 'response') >= 0.5, 1,0)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
rocCurve.fit1 <- roc(response = test.y, predictor = predictedClass)
plot(rocCurve.fit1, legacy.axes = T)
pROC::auc(rocCurve.fit1)
barchart(training.models$TARGET_FLAG2)
barchart(test.models$TARGET_FLAG2)
trainRows.models <- caret::createDataPartition(df.rev.cleaned$TARGET_FLAG2,p = 0.75, list = F)
training.models <- df.rev.cleaned[trainRows.models,]
test.models <- df.rev.cleaned[-trainRows.models,]
y <- ifelse(training.models$TARGET_FLAG2 == "No",0,1)
x <- as.matrix(training.models[ ,c(PotentialPred[-7],colnames(training.models) [grep("JOB_", colnames(training.models))])])
dffit <- data.frame(y,x)
fit1 <- glm(y~.,family = binomial,data = dffit[complete.cases(dffit),])
summary(fit1)
x.test <- test.models[ ,c(PotentialPred[-7],colnames(training.models) [grep("JOB_", colnames(training.models))])]
predictedClass <- ifelse(predict.glm(fit1,newdata = x.test, type = 'response') >= 0.5, 1,0)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
rocCurve.fit1 <- roc(response = test.y, predictor = predictedClass)
plot(rocCurve.fit1, legacy.axes = T)
pROC::auc(rocCurve.fit1)
x2 <- as.matrix(training.models[,c("AGE","INCOME","TRAVTIME","BLUEBOOK","OLDCLAIM","CLM_FREQ","MVR_PTS")])
dfit2 <- data.frame(y,x2)
fit2 <- glm(y~.,family = binomial,data = dffit2[complete.cases(dffit2),])
dfit2 <- data.frame(y,x2)
fit2 <- glm(y~.,family = binomial,data = dffit2[complete.cases(dffit2),])
fit2 <- glm(y~.,family = binomial,data = dfit2[complete.cases(dfit2),])
summary(fit2)
pROC::roc(fit2)
x2.test <- test.models[,c("AGE","INCOME","TRAVTIME","BLUEBOOK","OLDCLAIM","CLM_FREQ","MVR_PTS")]
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.5, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
plot(rocCurve.fit2, legacy.axes = T)
pROC::auc(rocCurve.fit2)
plot(predict.glm(fit2,newdata = x2.test, type = 'response'))
plot(predictedClass2)
plot(test.y)
summary(fit2)
table(predictedClass2,test.y)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.3, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
table(predictedClass2,test.y)
plot(rocCurve.fit2, legacy.axes = T)
pROC::auc(rocCurve.fit2)
table(predictedClass2,test.y)
pROC::auc(rocCurve.fit2)
summary(fit2)
pROC::auc(rocCurve.fit2)
plot(rocCurve.fit2, legacy.axes = T)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.4, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
table(predictedClass2,test.y)
plot(rocCurve.fit2, legacy.axes = T)
pROC::auc(rocCurve.fit2)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.3, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
table(predictedClass2,test.y)
plot(rocCurve.fit2, legacy.axes = T)
pROC::auc(rocCurve.fit2)
table(predictedClass2,test.y)
tab <- table(predictedClass2,test.y)
prop.table(tab,1)
prop.table(tab,2)
tab
(233 + 359) / sum(233,359,1059,274)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.4, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
tab <- table(predictedClass2,test.y)
diag(tab)
tab
nrow(x2.test)
nrow(x2.test) - sum(diag(tab)) / nrow(x2.test)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.35, 1,0)
tab <- table(predictedClass2,test.y)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.5, 1,0)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
tab <- table(predictedClass2,test.y)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.3, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
tab <- table(predictedClass2,test.y)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.4, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
tab <- table(predictedClass2,test.y)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.35, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
tab <- table(predictedClass2,test.y)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.4, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
tab <- table(predictedClass2,test.y)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.3, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
tab <- table(predictedClass2,test.y)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.45, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
tab <- table(predictedClass2,test.y)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
fit2 <- glm(y~.,family = binomial,data = dfit2)
summary(fit2)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.5, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
tab <- table(predictedClass2,test.y)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
plot(rocCurve.fit2, legacy.axes = T)
pROC::auc(rocCurve.fit2)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
x2 <- as.matrix(training.models[,c("AGE","INCOME","TRAVTIME","BLUEBOOK","OLDCLAIM","CLM_FREQ","MVR_PTS")])
x2.test <- test.models[,c("AGE","INCOME","TRAVTIME","BLUEBOOK","OLDCLAIM","CLM_FREQ","MVR_PTS")]
dfit2 <- data.frame(y,x2)
fit2 <- glm(y~.,family = binomial,data = dfit2)
summary(fit2)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.5, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
tab <- table(predictedClass2,test.y)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
plot(rocCurve.fit2, legacy.axes = T)
pROC::auc(rocCurve.fit2)
summary(training)
PotentialPred <- rownames(tr.boosted$importance)[order(tr.boosted$importance,decreasing = T)][1:12]
#df.rev.imputed <- VIM::kNN(df.rev.cleaned)
#
trainRows.models <- caret::createDataPartition(df.rev.cleaned$TARGET_FLAG2,p = 0.75, list = F)
training.models <- df.rev.cleaned[trainRows.models,]
test.models <- df.rev.cleaned[-trainRows.models,]
y <- ifelse(training.models$TARGET_FLAG2 == "No",0,1)
x <- as.matrix(training.models[ ,c(PotentialPred[-7],colnames(training.models) [grep("JOB_", colnames(training.models))])])
dffit <- data.frame(y,x)
fit1 <- glm(y~.,family = binomial,data = dffit[complete.cases(dffit),])
summary(fit1)
x.test <- test.models[ ,c(PotentialPred[-7],colnames(training.models) [grep("JOB_", colnames(training.models))])]
predictedClass <- ifelse(predict.glm(fit1,newdata = x.test, type = 'response') >= 0.5, 1,0)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
rocCurve.fit1 <- roc(response = test.y, predictor = predictedClass)
plot(rocCurve.fit1, legacy.axes = T)
pROC::auc(rocCurve.fit1)
x2 <- as.matrix(training.models[,c("AGE","INCOME","TRAVTIME","BLUEBOOK","OLDCLAIM","CLM_FREQ","MVR_PTS")])
x2.test <- test.models[,c("AGE","INCOME","TRAVTIME","BLUEBOOK","OLDCLAIM","CLM_FREQ","MVR_PTS")]
dfit2 <- data.frame(y,x2)
fit2 <- glm(y~.,family = binomial,data = dfit2)
summary(fit2)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.5, 1,0)
rocCurve.fit2 <- roc(response = test.y, predictor = predictedClass2)
tab <- table(predictedClass2,test.y)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
plot(rocCurve.fit2, legacy.axes = T)
pROC::auc(rocCurve.fit2)
plot.roc(test.y,predictedClass2)
tab <- table(predictedClass2,test.models$TARGET_FLAG)
rocCurve.fit2 <- roc(response = test.models$TARGET_FLAG, predictor = predictedClass2)
tab <- table(predictedClass2,test.models$TARGET_FLAG)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
pROC::auc(rocCurve.fit1)
rocCurve.fit2 <- roc(response = test.models$TARGET_FLAG, predictor = predictedClass2)
tab <- table(predictedClass2,test.models$TARGET_FLAG)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
plot(rocCurve.fit2, legacy.axes = T)
pROC::auc(rocCurve.fit2)
write.csv(df.rev.cleaned, file = 'dfrevcleaned.csv')
a = (0:100)/100 # different cut points, don’t call it c! tpr = rep(NA, 101) # true positive rate
fpr = rep(NA, 101) # false positive rate denom=table(default$default)
for(i in 1:101){ num=table(x2.test[fit2$fitted.values>=a[i]]) fpr[i] = num[1]/denom[1]
tpr[i] = num[2]/denom[2]
}
plot(fpr, tpr, type="l", xlab="False Positive Rate", ylab="True Positive Rate") abline(0,1)
a = (0:100)/100 # different cut points, don’t call it c! tpr = rep(NA, 101) # true positive rate
fpr = rep(NA, 101) # false positive rate denom=table(default$default)
for(i in 1:101){ num=table(x2.test[fit2$fitted.values>=a[i]]) fpr[i] = num[1]/denom[1]
tpr[i] = num[2]/denom[2]
}
a = (0:100)/100 # different cut points, don’t call it c! tpr = rep(NA, 101) # true positive rate
fpr = rep(NA, 101) # false positive rate denom=table(default$default)
for(i in 1:101)
{ num=table(x2.test[fit2$fitted.values>=a[i]]) fpr[i] = num[1]/denom[1]
tpr[i] = num[2]/denom[2]
}
for(i in 1:101) {
num=table(x2.test[fit2$fitted.values>=a[i]]) fpr[i] = num[1]/denom[1]
tpr[i] = num[2]/denom[2]
}
for(i in 1:101) {
num <- table(x2.test[fit2$fitted.values>=a[i]]) fpr[i] = num[1]/denom[1]
tpr[i]  <-  num[2]/denom[2]
}
for(i in 1:101) {
num <- table(x2.test[fit2$fitted.values>=a[i]])
fpr[i] <- num[1]/denom[1]
tpr[i]  <-  num[2]/denom[2]
}
fit2$fitted.values
tpr = rep(NA, 101)
for(i in 1:101) {
num <- table(x2.test[fit2$fitted.values>=a[i]])
fpr[i] <- num[1]/denom[1]
tpr[i]  <-  num[2]/denom[2]
}
x2.test[fit2$fitted.values>=a[i]]
for(i in 1:101) {
num <- table(test.y[fit2$fitted.values>=a[i]])
fpr[i] <- num[1]/denom[1]
tpr[i]  <-  num[2]/denom[2]
}
denom=table(test.y)
denom
a = (0:100)/100 # different cut points, don’t call it c! tpr = rep(NA, 101) # true positive rate
fpr = rep(NA, 101) # false positive rate denom=table(default$default)
tpr = rep(NA, 101)
denom=table(test.y)
for(i in 1:101) {
num <- table(test.y[fit2$fitted.values>=a[i]])
fpr[i] <- num[1]/denom[1]
tpr[i]  <-  num[2]/denom[2]
}
plot(fpr, tpr, type="l", xlab="False Positive Rate", ylab="True Positive Rate") abline(0,1)
plot(fpr, tpr, type="l", xlab="False Positive Rate", ylab="True Positive Rate")
abline(0,1)
b = (0:10)*10+1
points(fpr[b], tpr[b], pch=16)
text(fpr[b[-1]]+.01, tpr[b[-1]], paste("c=",as.character(a[b[-1]])), adj=0) text(1,.98, "c=0")
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
tab
tab''
transpose(tab)
t(tab)
sum(tab)
rocCurve.fit.train <- roc(response = training.models$TARGET_FLAG, predictor = fit2$fitted.values)
fit2$fitted.values
plot(fit2$fitted.values)
length(fit2$fitted.values)
nrow(dfit2)
fit2 <- glm(y~.,family = binomial,data = dfit2)
summary(fit2)
VIM::aggr(dffit, prop = F, numbers = T)
VIM::aggr(dffit, prop = F, numbers = T)
VIM::aggr(dffit)
VIM::aggr(df)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
x2 <- as.matrix(training.models[,c("AGE","INCOME","TRAVTIME","BLUEBOOK","OLDCLAIM","CLM_FREQ","MVR_PTS")])
x2.test <- test.models[,c("AGE","INCOME","TRAVTIME","BLUEBOOK","OLDCLAIM","CLM_FREQ","MVR_PTS")]
dfit2 <- data.frame(y,x2)
fit2 <- glm(y~.,family = binomial,data = dfit2)
summary(fit2)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.4, 1,0)
rocCurve.fit2 <- roc(response = test.models$TARGET_FLAG, predictor = predictedClass2)
tab <- table(predictedClass2,test.models$TARGET_FLAG)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.5, 1,0)
rocCurve.fit2 <- roc(response = test.models$TARGET_FLAG, predictor = predictedClass2)
tab <- table(predictedClass2,test.models$TARGET_FLAG)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.3, 1,0)
rocCurve.fit2 <- roc(response = test.models$TARGET_FLAG, predictor = predictedClass2)
tab <- table(predictedClass2,test.models$TARGET_FLAG)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.6, 1,0)
rocCurve.fit2 <- roc(response = test.models$TARGET_FLAG, predictor = predictedClass2)
tab <- table(predictedClass2,test.models$TARGET_FLAG)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.5, 1,0)
rocCurve.fit2 <- roc(response = test.models$TARGET_FLAG, predictor = predictedClass2)
tab <- table(predictedClass2,test.models$TARGET_FLAG)
(nrow(x2.test) - sum(diag(tab))) / nrow(x2.test)
rocCurve.fit2.train <- roc(response = y, predictor = fit2$fitted.values)
rocCurve.fit2.train <- roc(response = y, predictor = predictedClass2)
rocCurve.fit2.train <- roc(response = dfit2$y, predictor = predictedClass2)
rocCurve.fit2.train <- roc(response = dfit2$y[complete.cases(dfit2),], predictor = predictedClass2)
rocCurve.fit2.train <- roc(response = dfit2[complete.cases(dfit2),'y'], predictor = predictedClass2)
nrow(dfit2[complete.cases(dfit2),])
nrow(predictedClass2)
length(predictedClass2)
predictedClass2.train <- ifelse(fit2$fitted.values >= 0.5,1,0)
predictedClass2 <- ifelse(predict.glm(fit2,newdata = x2.test, type = 'response') >= 0.5, 1,0)
rocCurve.fit2 <- roc(response = test.models$TARGET_FLAG, predictor = predictedClass2.train)
rocCurve.fit2 <- roc(response = dfit2$y, predictor = predictedClass2.train)
rocCurve.fit2.train <- roc(response = dfit2[complete.cases(dfit2),'y'], predictor = predictedClass2.train)
roc(rocCurve.fit2.train)
roc(response = test.models$TARGET_FLAG, predictor = predictedClass2)
roc(response = dfit2[complete.cases(dfit2),'y'], predictor = predictedClass2.train)
plot(rocCurve.fit2.train)
plot.roc(rocCurve.fit2.train)
pROC::auc(rocCurve.fit2.train)
write.csv(dfit2, file = "dfit2.csv")
summary(fit2)
plot.roc(rocCurve.fit2.train,algorithm = 2)
plot.roc(rocCurve.fit2.train,algorithm = 3)
plot.roc(rocCurve.fit2.train,algorithm = 1)
summary(fit2)
rocCurve.fit2.train <- roc(response = dfit2[complete.cases(dfit2),'y'], predictor = predictedClass2.train)
summary(fit2)
rocCurve.fit2.train <- roc(response = dfit2[complete.cases(dfit2),'y'], predictor = predictedClass2.train)
plot(rocCurve.fit2.train)
install.packages("ROCR")
library(ROCR)
ROCR.simple <- data("ROCR.simple")
head(ROCR.simple)
ROCR.simple <- data(ROCR.simple)
head(ROCR.simple)
data("ROCR.simple")
ROCR.simple$predictions
ROCR.simple$labels
pred <- prediction(ROCR.simple$predictions, ROCR.simple$labels)
pred
perf <- performance(pred,"tpr","fpr")
perf
plot(perf,colorize=TRUE)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
simulatedTrain <- quadBoundaryFunc(500)
View(simulatedTrain)
simulatedTest <- quadBoundaryFunc(1000)
library(randomForest)
rfModel <- rando,randomForest(class ~ X1 + X2, data = simulatedTrain, ntree = 200)
rfModel <- randomForest(class ~ X1 + X2, data = simulatedTrain, ntree = 200)
plot(rfModel)
knitr::opts_chunk$set(echo = F, warning = F, message = F)
# import data
df <- read.csv('logit_insurance_rev.csv')
# Sanity Check of numeric variables
library(mosaic)
sanitycheck <- do.call(rbind,dfapply(df,favstats, select = is.numeric))
knitr::kable(round(sanitycheck,2), caption = "Summary statistics")
# Sanoty check on non-numeric variables
sanitycheckcharacter <-select(df, colnames(df[1,sapply(df,class) == 'factor']))
library(purrr)
UniqueVals <- sanitycheckcharacter %>%
map(unique)
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(df,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,function(x)length(x[which(x == " ")]))),
row.names = names(UniqueVals))
colnames(Counts) <- c( "# Unique", "n","missing","Blanks")
knitr::kable(Counts, caption = 'Sanity check of non numeric variables')
# Creating attribute columns for missing variables
df.rev <- df %>%
dplyr::mutate(YOJ_Missing = ifelse(is.na(YOJ),1,0)) %>%
dplyr::mutate(Income_Missing = ifelse(is.na(INCOME),1,0)) %>%
dplyr::mutate(HOME_Val_Missing = ifelse(is.na(HOME_VAL),1,0)) %>%
dplyr::mutate(CAR_AGE_Missing = ifelse(is.na(CAR_AGE),1,0)) %>%
dplyr::mutate(AGE_Missing = ifelse(is.na(AGE),1,0)) %>%
dplyr::mutate(CAR_AGE = ifelse(!is.na(CAR_AGE) & CAR_AGE <0, abs(CAR_AGE), CAR_AGE))
# save file for external data analysis
# write.table(df.rev,'insurancedata.csv')
# Defining predictors and temporarily removing Target amount from the data
predictors <- colnames(df.rev)[which(colnames(df.rev) %in% c("INDEX", "TARGET_AMT"))*-1]
df.rev.cleaned <- df.rev %>%
dplyr::select(c('TARGET_FLAG',predictors))
write.csv(df.rev.cleaned, file = 'dfrevcleaned.csv')
# creating indicator variables for factor variables
factorcols <- sapply(df.rev.cleaned,is.factor)
dummyvars <- dummy::dummy(df.rev.cleaned[,factorcols],int = T)
df.rev.cleaned <- cbind(df.rev.cleaned,dummyvars)
#df.rev.cleaned.comp <- df.rev.cleaned[complete.cases(df.rev.cleaned), c(- 1,-7,-23:-27)]
library(forcats)
library(ggplot2)
ggplot(data = df.rev.cleaned[!is.na(df.rev.cleaned$INCOME),], mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip() + theme_bw() + xlab("JOB") + geom_vline(xintercept = 4.5,linetype = "dashed", color = "red") + theme(legend.position = "none")
df.rev.cleaned <- df.rev.cleaned %>% dplyr::mutate(JOB.category = ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
corcols <- sapply(df.rev.cleaned,is.numeric)
corcols[grep("_Missing",colnames(df.rev.cleaned))] <- F
cordata <- cor(df.rev.cleaned[complete.cases(df.rev.cleaned), corcols])
corrplot::corrplot(cordata,tl.cex = 0.6)
set.seed(10)
df.rev.cleaned$TARGET_FLAG2 <- ifelse(df.rev.cleaned$TARGET_FLAG==1,"Yes", "No")
trainRows <- caret::createDataPartition(df.rev.cleaned$TARGET_FLAG2,p = 0.8, list = F)
training <- df.rev.cleaned[trainRows,]
test <- df.rev.cleaned[-trainRows,]
tr2 <- rpart::rpart(TARGET_FLAG2 ~. - TARGET_FLAG, data = training,parms = list(split = 'AUC'))
tr2 <- rpart::rpart(TARGET_FLAG2 ~. - TARGET_FLAG, data = training,parms = list(split = 'AUC'))
summary(tr2)
plot(tr2)
text(tr2, use.n = TRUE,cex = 0.5,pretty = 0)
tr.boosted <- randomForest::randomForest(as.factor(TARGET_FLAG2) ~ . - TARGET_FLAG, data = training,na.action=na.omit,mtry = 28)
plot(tr.boosted)
rftest <- predict(object = rfModel, simulatedTest, type = "response")
rftest
rftest.class <- predict(object = rfModel, simulatedTest, type = "response")
rftest.prob <- predict(object = rfModel, simulatedTest, type = 'prob')
rftest.prob
??predict
test$predicted <- predict(tr.boosted,newdata = test,type = 'response')
test$predicted.class <- predict(tr.boosted,newdata = test,type = 'response')
test$predicted.prob <- predict(tr.boosted,newdata = test,type = 'prob')
test$predicted.prob
head(test$predicted.prob)
test$predicted.prob <- predict(tr.boosted,newdata = test,type = 'prob')[,"Yes"]
head(test$predicted.prob)
rocCurve <- roc(response = test$predicted.class , predictor = test$predicted.prob)
library(pROC)
rocCurve <- roc(response = test$predicted.class , predictor = test$predicted.prob)
plot(rocCurve, legacy.axes = T,xlim = c(1,0), ylim = c(0,1))
pROC::auc(rocCurve)
plot(rocCurve, legacy.axes = T,xlim = c(1,0), ylim = c(0,1))
rocCurve <- roc(response = test$TARGET_FLAG , predictor = test$predicted.prob)
plot(rocCurve, legacy.axes = T,xlim = c(1,0), ylim = c(0,1))
pROC::auc(rocCurve)
PotentialPred <- rownames(tr.boosted$importance)[order(tr.boosted$importance,decreasing = T)][1:12]
trainRows.models <- caret::createDataPartition(df.rev.cleaned$TARGET_FLAG2,p = 0.75, list = F)
training.models <- df.rev.cleaned[trainRows.models,]
test.models <- df.rev.cleaned[-trainRows.models,]
y <- ifelse(training.models$TARGET_FLAG2 == "No",0,1)
x <- as.matrix(training.models[ ,c(PotentialPred[-7],colnames(training.models) [grep("JOB_", colnames(training.models))])])
dffit <- data.frame(y,x)
fit1 <- glm(y~.,family = binomial,data = dffit[complete.cases(dffit),])
summary(fit1)
head(fit1$fitted.values)
fit1.pred <- predict(fit1,newdata = dffit, type = 'prob')
fit1.pred <- predict(fit1,newdata = dffit, type = 'link')
head(fit1.pred)
fit1.pred <- predict(fit1,newdata = dffit, type = 'terms')
rocCurve.fit1.train <- roc(response = dfit$y, predictor = fit1$fitted.values)
PotentialPred <- rownames(tr.boosted$importance)[order(tr.boosted$importance,decreasing = T)][1:12]
trainRows.models <- caret::createDataPartition(df.rev.cleaned$TARGET_FLAG2,p = 0.75, list = F)
training.models <- df.rev.cleaned[trainRows.models,]
test.models <- df.rev.cleaned[-trainRows.models,]
y <- ifelse(training.models$TARGET_FLAG2 == "No",0,1)
x <- as.matrix(training.models[ ,c(PotentialPred[-7],colnames(training.models) [grep("JOB_", colnames(training.models))])])
dffit <- data.frame(y,x)
fit1 <- glm(y~.,family = binomial,data = dffit[complete.cases(dffit),])
summary(fit1)
rocCurve.fit1.train <- roc(response = dfit$y, predictor = fit1$fitted.values)
rocCurve.fit1.train <- roc(response = dffit$y, predictor = fit1$fitted.values)
rocCurve.fit1.train <- roc(response = dffit[complete.cases(dffit),"y"], predictor = fit1$fitted.values)
plot(rocCurve.fit1.train)
auc(rocCurve.fit1.train)
x2 <- as.matrix(training.models[,c("AGE","INCOME","TRAVTIME","BLUEBOOK","OLDCLAIM","CLM_FREQ","MVR_PTS")])
x2.test <- test.models[,c("AGE","INCOME","TRAVTIME","BLUEBOOK","OLDCLAIM","CLM_FREQ","MVR_PTS")]
x.test <- test.models[ ,c(PotentialPred[-7],colnames(training.models) [grep("JOB_", colnames(training.models))])]
predictedClass <- ifelse(predict.glm(fit1,newdata = x.test, type = 'response') >= 0.5, 1,0)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
rocCurve.fit1 <- roc(response = test.y, predictor = predict.glm(fit1,newdata = x.test, type = 'response'))
plot(rocCurve.fit1, legacy.axes = T)
pROC::auc(rocCurve.fit1)
auc(rocCurve.fit1.train)
plot(rocCurve.fit1, legacy.axes = T)
x2 <- as.matrix(training.models[,c("AGE","INCOME","TRAVTIME","BLUEBOOK","OLDCLAIM","CLM_FREQ","MVR_PTS")])
x2.test <- test.models[,c("AGE","INCOME","TRAVTIME","BLUEBOOK","OLDCLAIM","CLM_FREQ","MVR_PTS")]
dfit2 <- data.frame(y,x2)
write.csv(dfit2, file = "dfit2.csv")
fit2 <- glm(y~.,family = binomial,data = dfit2)
rocCurve.fit2 <- roc(response = test.models$TARGET_FLAG, predictor = fit2$fitted.values)
rocCurve.fit2 <- roc(response = test.models[complete.cases(test.models),TARGET_FLAG], predictor = fit2$fitted.values)
rocCurve.fit2 <- roc(response = test.models[complete.cases(test.models),'TARGET_FLAG'], predictor = fit2$fitted.values)
rocCurve.fit2 <- roc(response = dfit2$y, predictor = fit2$fitted.values)
rocCurve.fit2 <- roc(response = dfit2[complete.cases(dfit2),'y'], predictor = fit2$fitted.values)
plot(rocCurve.fit2)
auc(rocCurve.fit2)
