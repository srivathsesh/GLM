tr.boosted <- randomForest::randomForest(TARGET_FLAG2 ~ . - TARGET_FLAG, data = training,na.action=na.omit,mtry = 28)
tr.boosted
randomForest::varImpPlot(tr.boosted, cex = 0.7)
library(pROC)
test$predicted <- predict(tr.boosted,newdata = test)
table(test$TARGET_FLAG2, test$predicted)
roc(reponse = test$TARGET_FLAG2, predictor = test$predicted)
roc(reponse = as.numeric(test$TARGET_FLAG2), predictor = as.numeric(test$predicted))
View(test)
View(test)
rocCurve <- roc(reponse = ifelse(test$TARGET_FLAG2=="Yes",1,0), predictor = ifelse(test$predicted=="Yes",1,0))
rocCurve <- roc(reponse = as.numeric(ifelse(test$TARGET_FLAG2=="Yes",1,0)), predictor = as.numeric(ifelse(test$predicted=="Yes",1,0)))
rocCurve <- roc(reponse = as.factor(ifelse(test$TARGET_FLAG2=="Yes",1,0)), predictor = as.factor(ifelse(test$predicted=="Yes",1,0)))
as.factor(ifelse(test$TARGET_FLAG2=="Yes",1,0)
)
test$predicted <- predict(tr.boosted,newdata = test)
test$predicted <- ifelse(test$predicted == "Yes", 1,0)
test$TARGET_FLAG2 <- ifelse(test$TARGET_FLAG2 == "Yes",1,0)
roc(response = test$TARGET_FLAG2, predictor = test$predicted)
plot(roc(response = test$TARGET_FLAG2, predictor = test$predicted),legacy.axes = T)
plot(roc(response = test$TARGET_FLAG2, predictor = test$predicted))
rocCurve <- roc(response = test$TARGET_FLAG2, predictor = test$predicted)
plot(rocCurve)
plot(rocCurve, legacy.axes = T)
plot(rocCurve, legacy.axes = T, xlim(c(0,1)))
plot(rocCurve, legacy.axes = T, xlim(0,1))
plot(rocCurve, legacy.axes = T)
plot(rocCurve, legacy.axes = T, xlim = c(0,1))
plot(rocCurve, legacy.axes = T, xlim = c(1,0))
plot(rocCurve, legacy.axes = T, xlim = c(1,0))
plot(rocCurve, legacy.axes = T)
plot(rocCurve, legacy.axes = T)
plot(rocCurve)
plot(rocCurve)
plot(rocCurve, legacy.axes = T)
plot(rocCurve, legacy.axes = T)
plot(rocCurve, legacy.axes = T,xlim = c(0,1))
plot(rocCurve, legacy.axes = T,xlim = c(1,0))
plot(rocCurve, legacy.axes = T,xlim = c(1,0), ylim = c(0,1))
randomForest::varImpPlot(tr.boosted, cex = 0.7)
knitr::kable(round(sanitycheck,2), caption = "Summary statistics")
sum(is.na(df$JOB))
is.na(df$JOB)
sum(is.na(df$CAR_TYPE))
1 2 3
training.imputed <- VIM::kNN(training)
summary(training.imputed)
training.imputed %>% filter(INCOME_imp == T) %>% filter(JOB == 'Home Maker') %>% hist(INCOME)
training.imputed %>% filter(INCOME_imp == T) %>% filter(JOB == 'Home Maker')
training.imputed %>% filter(INCOME_imp == T) %>% filter(JOB == 'Home Maker') %>% histogram(INCOME)
training.imputed %>% filter(INCOME_imp == T) %>% filter(JOB == 'Home Maker') %>% histogram(as.numeric(INCOME))
training.imputed %>% filter(INCOME_imp == T) %>% filter(JOB == 'Home Maker') %>% histogram(as.numeric($INCOME))
training.imputed %>% filter(INCOME_imp == T) %>% filter(JOB == 'Home Maker') %>% select(INCOME) %>%  histogram(INCOME)
yedho <-training.imputed %>% filter(INCOME_imp == T) %>% filter(JOB == 'Home Maker') %>% select(INCOME)
histogram(yedho)
histogram(yedho$INCOME)
plot(rocCurve, legacy.axes = T,xlim = c(1,0), ylim = c(0,1))
knitr::opts_chunk$set(echo = F, warning = F, message = F)
sanitycheckcharacter <-select(df.rev, colnames(df.rev[1,sapply(df.rev,class) == 'character']))
sanitycheckcharacter
sapply(df.rev,class) == 'character'
sanitycheckcharacter <-select(df.rev, colnames(df.rev[1,sapply(df.rev,class) == 'Factor']))
sanitycheckcharacter
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(sanitycheckcharacter,length,select = is.character)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.character)),row.names = names(UniqueVals))
sapply(df.rev,class) == 'Factor'
sapply(df.rev,class) == 'factor'
library(purrr)
UniqueVals <- sanitycheckcharacter %>%
map(unique)
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(sanitycheckcharacter,length,select = is.character)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.character)),row.names = names(UniqueVals))
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(sanitycheckcharacter,length,select = is.character)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),row.names = names(UniqueVals))
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(sanitycheckcharacter,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),row.names = names(UniqueVals))
UniqueVals
sanitycheckcharacter
sanitycheckcharacter <-select(df.rev, colnames(df.rev[1,sapply(df.rev,class) == 'factor']))
sanitycheckcharacter
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(sanitycheckcharacter,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),row.names = names(UniqueVals))
data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(sanitycheckcharacter,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),row.names = names(UniqueVals))
sapply(UniqueVals,length)
UniqueVals
library(purrr)
UniqueVals <- sanitycheckcharacter %>%
map(unique)
UniqueVals
sapply(UniqueVals,length)
do.call(rbind,dfapply(sanitycheckcharacter,length,select = is.factor))
do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor))
names(UniqueVals)
data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(sanitycheckcharacter,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),row.names = names(UniqueVals))
View(.Last.value)
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(sanitycheckcharacter,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),row.names = names(UniqueVals))
Counts
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(sanitycheckcharacter,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.na)),row.names = names(UniqueVals))
dfapply(sanitycheckcharacter,n_missing)
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(df,length,select = is.factor)),do.call(rbind,dfapply(df,n_missing,select = is.factor)),row.names = names(UniqueVals))
colnames(Counts) <- c( "# Unique", "n","missing")
Counts
dfapply(df,n_missing,select = is.character)
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(df,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),row.names = names(UniqueVals))
Counts
dfapply(sanitycheckcharacter,n_missing)
dfapply(df,n_missing)
knitr::kable(Counts, caption = 'Sanity check of non numeric variables')
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(df,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),row.names = names(UniqueVals))
colnames(Counts) <- c( "# Unique", "n","missing")
knitr::kable(Counts, caption = 'Sanity check of non numeric variables')
tr <- tree::tree(TARGET_FLAG2 ~. - TARGET_FLAG, data = df.rev.cleaned)
summary(tr)
tr <- tree::tree(TARGET_FLAG2 ~. - TARGET_FLAG, data = training)
summary(tr)
cv.tr <- tree::cv.tree(tr,FUN = prune.misclass,K = 100)
summary(cv.tr)
plot(prune.misclass(cv.tr,best = 5))
library(tree)
plot(prune.misclass(cv.tr,best = 5))
cv.tr
tr <- tree::tree(TARGET_FLAG2 ~. - TARGET_FLAG, data = df.rev.cleaned)
summary(tr)
cv.tr <- tree::cv.tree(tr,FUN = prune.misclass,K = 100)
cv.tr
tr2 <- rpart::rpart(TARGET_FLAG2 ~. - TARGET_FLAG, data = training,parms = list(split = 'gini'))
summary(tr2)
plot(tr2)
text(tr2, use.n = TRUE)
tr.boosted <- randomForest::randomForest(TARGET_FLAG2 ~ . - TARGET_FLAG, data = training,na.action=na.omit,mtry = 28)
tr.boosted
randomForest::varImpPlot(tr.boosted, cex = 0.7)
text(tr2, use.n = TRUE,cex = 0.5)
plot(tr2)
text(tr2, use.n = TRUE,cex = 0.5)
plot(tr2)
text(tr2, use.n = TRUE,cex = 0.5)
trainRows <- caret::createDataPartition(df.rev.cleaned$TARGET_FLAG2,p = 0.8, list = F)
training <- df.rev.cleaned[trainRows,]
test <- df.rev.cleaned[-trainRows,]
tr <- tree::tree(TARGET_FLAG2 ~. - TARGET_FLAG, data = training)
summary(tr)
cv.tr <- tree::cv.tree(tr,FUN = prune.misclass,K = 100)
library(tree)
plot(prune.misclass(cv.tr,best = 5))
plot(prune.misclass(cv.tr,best = 5))
tr <- tree::tree(TARGET_FLAG2 ~. - TARGET_FLAG, data = training)
summary(tr)
cv.tr <- tree::cv.tree(tr,FUN = prune.misclass,K = 100)
library(tree)
plot(prune.misclass(cv.tr,best = 5))
text(prune.misclass(cv.tr,best = 5),pretty = 0)
plot(prune.misclass(cv.tr,best = 5))
summary(tr)
tree::cv.tree(tr,FUN = prune.misclass,K = 100)
cv.tr <- tree::cv.tree(tr,FUN = prune.misclass,K = 100)
library(tree)
plot(prune.misclass(cv.tr,best = 5))
plot(tr)
cv.tr <- tree::cv.tree(tr,FUN = prune.misclass,K = 100)
plot(cv.tr)
plot(cv.tr,best = 5)
tr2 <- rpart::rpart(TARGET_FLAG2 ~. - TARGET_FLAG, data = training,parms = list(split = 'gini'))
summary(tr2)
misclass.tree(tr2)
misclass.tree(tr)
tr.boosted <- randomForest::randomForest(TARGET_FLAG2 ~ . - TARGET_FLAG, data = training,na.action=na.omit,mtry = 28)
tr.boosted
randomForest::varImpPlot(tr.boosted, cex = 0.7)
library(pROC)
test$predicted <- predict(tr.boosted,newdata = test)
test$predicted <- ifelse(test$predicted == "Yes", 1,0)
test$TARGET_FLAG2 <- ifelse(test$TARGET_FLAG2 == "Yes",1,0)
rocCurve <- roc(response = test$TARGET_FLAG2, predictor = test$predicted)
plot(rocCurve, legacy.axes = T,xlim = c(1,0), ylim = c(0,1))
auc(rocCurve)
cv.tr <- tree::cv.tree(tr,FUN = prune.misclass,K = 100)
prune.misclass(cv.tr,best = 5)
prune.misclass(cv.tr)
prune.misclass(tr)
cv.tree(tr,FUN = prune.misclass,K = 100)
plot(prune.misclass(cv.tr,best = 5))
library(tree)
plot(prune.misclass(cv.tr,best = 5))
cv.tr <- cv.tree(tr,FUN = prune.misclass,K = 100)
plot(prune.misclass(cv.tr,best = 5))
tr.boosted$importance
order(tr.boosted$importance,decreasing = T)
rownames(tr.boosted$importance)[order(tr.boosted$importance,decreasing = T)]
PotentialPred <- rownames(tr.boosted$importance)[order(tr.boosted$importance,decreasing = T)][1:10]
y <- if_else(training$TARGET_FLAG2 == "No",0,1)
x <- training[,PotentialPred]
fit1 <- glm(y~x,family = binomial)
fit1 <- glm(y~as.matrix(x),family = binomial)
x <- as.matrix(training[,PotentialPred])
x <- training[,PotentialPred]
library(ggplot2)
ggplot(data = training, mapping = aes(x = INCOME, color = JOB)) + geom_density(alpha = 0.5)
ggplot(data = training, mapping = aes(y = INCOME, x = JOB,color = JOB)) + geom_boxplot()
ggplot(data = training, mapping = aes(x = INCOME, color = JOB)) + geom_density(fill = alpha = 0.5)
ggplot(data = training, mapping = aes(x = INCOME, color = JOB, fill = JOB)) + geom_density(alpha = 0.5)
ggplot(data = training, mapping = aes(x = INCOME, color = JOB, fill = JOB)) + geom_density(alpha = 0.5) + theme_classic()
library(tidyverse)
forcats::fct_reorder(f=training$JOB, x = training$INCOME, .desc = T)
ggplot(data = training, mapping = aes(y = fct_reorder(JOB,INCOME), x = JOB,color = JOB)) + geom_boxplot()
library(forcats)
ggplot(data = training, mapping = aes(y = fct_reorder(JOB,INCOME), x = JOB,color = JOB)) + geom_boxplot()
ggplot(data = training, mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
ggplot(data = training, mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot()
ggplot(data = training, mapping = aes(x = fct_reorder(JOB,mean(INCOME)), y = INCOME,color = JOB)) + geom_boxplot()
fct_reorder(training$JOB,mean(training$INCOME))
ggplot(data = training, mapping = aes(x = fct_reorder(JOB,mean(INCOME)), y = INCOME,color = JOB)) + geom_boxplot()
ggplot(data = training, mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
ggplot(data = training, mapping = aes(x = fct_reorder(JOB,mean(INCOME,na.rm = T)), y = INCOME,color = JOB)) + geom_boxplot()
ggplot(data = training, mapping = aes(x = fct_reorder(JOB,mean(INCOME)), y = INCOME,color = JOB)) + geom_boxplot()
ggplot(data = training[!is.na(JOB),], mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
ggplot(data = training[!is.na(training$JOB),], mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
ggplot(data = training[!is.na(JOB),], mapping = aes(x = fct_reorder(JOB,INCOME,.desc = T), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
ggplot(data = training, mapping = aes(x = fct_reorder(JOB,INCOME,.desc = T), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
ggplot(data = training, mapping = aes(x = fct_reorder(x =JOB,y = INCOME,.desc = T), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
ggplot(data = training, mapping = aes(x = fct_reorder(f =JOB,y = INCOME,.desc = T), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
ggplot(data = training, mapping = aes(x = fct_reorder(f=JOB,y = INCOME,.desc = T), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
ggplot(data = training, mapping = aes(x = fct_reorder(f =JOB,x = INCOME,.desc = T,fun = median), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
ggplot(data = training, mapping = aes(x = fct_reorder(f =JOB,x = INCOME,.desc = T,fun = median), y = INCOME,color = JOB)) + geom_point() + coord_flip()
ggplot(data = training[!is.na(INCOME),], mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
ggplot(data = training[!is.na(training$INCOME),], mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
grep(" ", training$JOB)
grep(" ", df$JOB)
which(df$JOB = " ")
which(df$JOB =  " ")
which(df$JOB ==  " ")
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(df,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,function(x)length(x[which(x)== " "]))),
row.names = names(UniqueVals))
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(df,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,function(x)length(x[which(x) == " "]))),
row.names = names(UniqueVals))
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(df,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,function(x)length(x[which(x == " ")]))),
row.names = names(UniqueVals))
colnames(Counts) <- c( "# Unique", "n","missing","Blanks")
knitr::kable(Counts, caption = 'Sanity check of non numeric variables')
levels(training$JOB)
PotentialPred <- rownames(tr.boosted$importance)[order(tr.boosted$importance,decreasing = T)][1:10]
PotentialPred
ggplot(data = training[!is.na(training$INCOME),], mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip()
ggplot(data = training[!is.na(training$INCOME),], mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip() + theme_bw() + xlab("JOB")
ggplot(data = training[!is.na(training$INCOME),], mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip() + theme_bw() + xlab("JOB") + geom_vline(xintercept = 4.5,linetype = "dashed", color = "red")
ggplot(data = training[!is.na(training$INCOME),], mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip() + theme_bw() + xlab("JOB") + geom_vline(xintercept = 4.5,linetype = "dashed", color = "red")
df.rev.cleaned %>% dplyr::mutate(JOB.category <- ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
knitr::opts_chunk$set(echo = F, warning = F, message = F)
# import data
df <- read.csv('logit_insurance_rev.csv')
# Sanity Check of numeric variables
library(mosaic)
sanitycheck <- do.call(rbind,dfapply(df,favstats, select = is.numeric))
knitr::kable(round(sanitycheck,2), caption = "Summary statistics")
# Sanoty check on non-numeric variables
sanitycheckcharacter <-select(df, colnames(df.rev[1,sapply(df.rev,class) == 'factor']))
library(purrr)
UniqueVals <- sanitycheckcharacter %>%
map(unique)
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(df,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,function(x)length(x[which(x == " ")]))),
row.names = names(UniqueVals))
colnames(Counts) <- c( "# Unique", "n","missing","Blanks")
knitr::kable(Counts, caption = 'Sanity check of non numeric variables')
# Creating attribute columns for missing variables
df.rev <- df %>%
dplyr::mutate(YOJ_Missing = ifelse(is.na(YOJ),1,0)) %>%
dplyr::mutate(Income_Missing = ifelse(is.na(INCOME),1,0)) %>%
dplyr::mutate(HOME_Val_Missing = ifelse(is.na(HOME_VAL),1,0)) %>%
dplyr::mutate(CAR_AGE_Missing = ifelse(is.na(CAR_AGE),1,0)) %>%
dplyr::mutate(AGE_Missing = ifelse(is.na(AGE),1,0)) %>%
dplyr::mutate(CAR_AGE = ifelse(!is.na(CAR_AGE) & CAR_AGE <0, abs(CAR_AGE), CAR_AGE))
# save file for external data analysis
# write.table(df.rev,'insurancedata.csv')
# Defining predictors
predictors <- colnames(df.rev)[which(colnames(df.rev) %in% c("INDEX", "TARGET_AMT"))*-1]
df.rev.cleaned <- df.rev %>%
dplyr::select(c('TARGET_FLAG',predictors)) %>%
mutate(TARGET_FLAG2 = as.factor(ifelse(TARGET_FLAG, "Yes", "No")))
#df.rev.cleaned.comp <- df.rev.cleaned[complete.cases(df.rev.cleaned), c(- 1,-7,-23:-27)]
library(forcats)
library(ggplot2)
ggplot(data = training[!is.na(training$INCOME),], mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip() + theme_bw() + xlab("JOB") + geom_vline(xintercept = 4.5,linetype = "dashed", color = "red")
df.rev.cleaned %>% dplyr::mutate(JOB.category = ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
df.rev.cleaned <- df.rev.cleaned %>% dplyr::mutate(JOB.category = ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
knitr::opts_chunk$set(echo = F, warning = F, message = F)
# import data
df <- read.csv('logit_insurance_rev.csv')
# Sanity Check of numeric variables
library(mosaic)
sanitycheck <- do.call(rbind,dfapply(df,favstats, select = is.numeric))
knitr::kable(round(sanitycheck,2), caption = "Summary statistics")
# Sanoty check on non-numeric variables
sanitycheckcharacter <-select(df, colnames(df.rev[1,sapply(df.rev,class) == 'factor']))
library(purrr)
UniqueVals <- sanitycheckcharacter %>%
map(unique)
Counts <- data.frame(sapply(UniqueVals,length),
do.call(rbind,dfapply(df,length,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,n_missing,select = is.factor)),do.call(rbind,dfapply(sanitycheckcharacter,function(x)length(x[which(x == " ")]))),
row.names = names(UniqueVals))
colnames(Counts) <- c( "# Unique", "n","missing","Blanks")
knitr::kable(Counts, caption = 'Sanity check of non numeric variables')
# Creating attribute columns for missing variables
df.rev <- df %>%
dplyr::mutate(YOJ_Missing = ifelse(is.na(YOJ),1,0)) %>%
dplyr::mutate(Income_Missing = ifelse(is.na(INCOME),1,0)) %>%
dplyr::mutate(HOME_Val_Missing = ifelse(is.na(HOME_VAL),1,0)) %>%
dplyr::mutate(CAR_AGE_Missing = ifelse(is.na(CAR_AGE),1,0)) %>%
dplyr::mutate(AGE_Missing = ifelse(is.na(AGE),1,0)) %>%
dplyr::mutate(CAR_AGE = ifelse(!is.na(CAR_AGE) & CAR_AGE <0, abs(CAR_AGE), CAR_AGE))
# save file for external data analysis
# write.table(df.rev,'insurancedata.csv')
# Defining predictors
predictors <- colnames(df.rev)[which(colnames(df.rev) %in% c("INDEX", "TARGET_AMT"))*-1]
df.rev.cleaned <- df.rev %>%
dplyr::select(c('TARGET_FLAG',predictors)) %>%
mutate(TARGET_FLAG2 = as.factor(ifelse(TARGET_FLAG, "Yes", "No")))
#df.rev.cleaned.comp <- df.rev.cleaned[complete.cases(df.rev.cleaned), c(- 1,-7,-23:-27)]
library(forcats)
library(ggplot2)
ggplot(data = training[!is.na(training$INCOME),], mapping = aes(x = fct_reorder(JOB,INCOME), y = INCOME,color = JOB)) + geom_boxplot() + coord_flip() + theme_bw() + xlab("JOB") + geom_vline(xintercept = 4.5,linetype = "dashed", color = "red")
df.rev.cleaned <- df.rev.cleaned %>% dplyr::mutate(JOB.category = ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
trainRows <- caret::createDataPartition(df.rev.cleaned$TARGET_FLAG2,p = 0.8, list = F)
training <- df.rev.cleaned[trainRows,]
test <- df.rev.cleaned[-trainRows,]
# tr <- tree::tree(TARGET_FLAG2 ~. - TARGET_FLAG, data = training)
# summary(tr)
# cv.tr <- cv.tree(tr,FUN = prune.misclass,K = 100)
# library(tree)
# plot(prune.misclass(cv.tr,best = 5))
# text(prune.misclass(cv.tr,best = 5),pretty = 0)
tr2 <- rpart::rpart(TARGET_FLAG2 ~. - TARGET_FLAG, data = training,parms = list(split = 'gini'))
summary(tr2)
plot(tr2)
text(tr2, use.n = TRUE,cex = 0.5,pretty = 0)
tr.boosted <- randomForest::randomForest(TARGET_FLAG2 ~ . - TARGET_FLAG, data = training,na.action=na.omit,mtry = 28)
tr.boosted
randomForest::varImpPlot(tr.boosted, cex = 0.7)
library(pROC)
test$predicted <- predict(tr.boosted,newdata = test)
test$predicted <- ifelse(test$predicted == "Yes", 1,0)
test$TARGET_FLAG2 <- ifelse(test$TARGET_FLAG2 == "Yes",1,0)
rocCurve <- roc(response = test$TARGET_FLAG2, predictor = test$predicted)
plot(rocCurve, legacy.axes = T,xlim = c(1,0), ylim = c(0,1))
PotentialPred <- rownames(tr.boosted$importance)[order(tr.boosted$importance,decreasing = T)][1:10]
y <- if_else(training$TARGET_FLAG2 == "No",0,1)
x <- training[,c(PotentialPred[-6],"JOB.category")]
fit1 <- glm(y~as.matrix(x),family = binomial)
fit1 <- glm(y~x,family = binomial)
summary(training)
x <- training.imputed[,c(PotentialPred[-6],"JOB.category")]
df.rev.imputed <- VIM::kNN(df.rev.cleaned)
trainRows.models <- caret::createDataPartition(df.rev.imputed$TARGET_FLAG2,p = 0.8, list = F)
trainRows.models <- caret::createDataPartition(df.rev.imputed$TARGET_FLAG2,p = 0.8, list = F)
training.models <- df.rev.imputed[trainRows,]
test.models <- df.rev.imputed[-trainRows,]
y <- if_else(training.models$TARGET_FLAG2 == "No",0,1)
x <- training.models[,c(PotentialPred[-6],"JOB.category")]
fit1 <- glm(y~x,family = binomial)
fit1 <- glm(y~as.matrix(x),family = binomial)
c(PotentialPred[-6],"JOB.category")
PotentialPred
x <- training.models[,c(PotentialPred[-5],"JOB.category")]
fit1 <- glm(y~as.matrix(x),family = binomial)
PotentialPred
x <- training.models[,c(PotentialPred[c(-5,-8)],"JOB.category")]
fit1 <- glm(y~as.matrix(x),family = binomial)
summary(fit1)
PotentialPred
x <- as.matrix(training.models[,c(PotentialPred[c(-5,-8)])])
fit1 <- glm(y~x,family = binomial)
summary(fit1)
PotentialPred <- rownames(tr.boosted$importance)[order(tr.boosted$importance,decreasing = T)][1:10]
PotentialPred
y <- if_else(training.models$TARGET_FLAG2 == "No",0,1)
x <- as.matrix(training.models[,c(PotentialPred[c(-5,-7,-8)])])
fit1 <- glm(y~x,family = binomial)
summary(fit1)
fit1 <- glm(y~1,family = binomial)
summary(fit1)
fit1 <- glm(y~x,family = binomial)
summary(fit1)
deviance(fit1)/(6530-8)
predictedClass <- predict(fit1,newdata = test.models, type = "response")
plot(test.models$TARGET_FLAG2)
test.y <- if_else(test.models$TARGET_FLAG2 == "No",0,1))
test.y <- if_else(test.models$TARGET_FLAG2 == "No",0,1)
table(predicted,test.y)
table(predictedClass,test.y)
predictedClass <- predict(fit1,newdata = test.models, type = "response")
test.y <- if_else(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
summary(training)
PotentialPred <- rownames(tr.boosted$importance)[order(tr.boosted$importance,decreasing = T)][1:10]
df.rev.imputed <- VIM::kNN(df.rev.cleaned)
#
trainRows.models <- caret::createDataPartition(df.rev.imputed$TARGET_FLAG2,p = 0.8, list = F)
training.models <- df.rev.imputed[trainRows,]
test.models <- df.rev.imputed[-trainRows,]
y <- if_else(training.models$TARGET_FLAG2 == "No",0,1)
x <- as.matrix(training.models[,c(PotentialPred[c(-5,-7,-8)])])
fit1 <- glm(y~x,family = binomial)
fit1 <- glm(y~1,family = binomial)
summary(fit1)
predictedClass <- predict(fit1,newdata = test.models, type = "response")
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
plot(predictedClass)
predictedClass <- predict(fit1,newdata = test.models)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
plot(predictedClass)
fit1 <- glm(y~x,family = binomial)
predictedClass <- predict(fit1,newdata = test.models)
plot(predictedClass)
predictedClass <- predict(fit1,newdata = test.models,type = 'response')
table(predictedClass,test.y)
predictedClass <- predict(fit1,newdata = test.models,type = 'response')
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
View(x)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)[-1]
table(predictedClass,test.y)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)[-1]
dim(test.models)
training.models <- df.rev.imputed[trainRows.models,]
test.models <- df.rev.imputed[-trainRows,]
y <- if_else(training.models$TARGET_FLAG2 == "No",0,1)
x <- as.matrix(training.models[ ,c(PotentialPred[c(-5,-7,-8)])])
fit1 <- glm(y~x,family = binomial)
summary(fit1)
predictedClass <- predict(fit1,newdata = test.models,type = 'response')
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)[-1]
table(predictedClass,test.y)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
dim(test.y)
length(test.y)
length(test.models)
nrow(test.models)
length(predictedClass)
trainRows.models <- caret::createDataPartition(df.rev.imputed$TARGET_FLAG2,p = 0.8, list = F)
training.models <- df.rev.imputed[trainRows.models,]
test.models <- df.rev.imputed[-trainRows.models,]
y <- if_else(training.models$TARGET_FLAG2 == "No",0,1)
x <- as.matrix(training.models[ ,c(PotentialPred[c(-5,-7,-8)])])
fit1 <- glm(y~x,family = binomial)
summary(fit1)
predictedClass <- predict(fit1,newdata = test.models,type = 'response')
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
dim(test.models)
length(predictedClass)
predictedClass <- predict(fit1,newdata = test.models,type = 'response')
length(predictedClass)
fit1 <- glm(y~x,family = binomial)
summary(fit1)
predictedClass <- predict(fit1,newdata = test.models,type = 'response')
predictedClass <- predict(fit1,newdata = test.models)
test.models <- df.rev.imputed[-trainRows.models,]
predictedClass <- predict(fit1,newdata = test.models)
x.test <- as.matrix(test.models[ ,c(PotentialPred[c(-5,-7,-8)])])
predictedClass <- predict(fit1,newdata = x.test)
x.test <- test.models[ ,c(PotentialPred[c(-5,-7,-8)])]
predictedClass <- predict(fit1,newdata = x.test)
View(x.test)
trainRows.models <- caret::createDataPartition(df.rev.imputed$TARGET_FLAG2,p = 0.8, list = F)
training.models <- df.rev.imputed[trainRows.models,]
test.models <- df.rev.imputed[-trainRows.models,]
y <- ifelse(training.models$TARGET_FLAG2 == "No",0,1)
x <- as.matrix(training.models[ ,c(PotentialPred[c(-5,-7,-8)])])
fit1 <- glm(y~x,family = binomial)
summary(fit1)
x.test <- test.models[ ,c(PotentialPred[c(-5,-7,-8)])]
predictedClass <- predict(fit1,newdata = x.test)
predictedClass <- predict.glm(fit1,newdata = x.test)
summary(fit1)
dffit <- data.frame(y,x)
fit1 <- glm(y~.,family = binomial,data = dffit)
summary(fit1)
x.test <- test.models[ ,c(PotentialPred[c(-5,-7,-8)])]
predictedClass <- predict.glm(fit1,newdata = x.test)
predictedClass <- predict.glm(fit1,newdata = x.test, type = 'response')
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
plot(predictedClass)
predictedClass <- ifesle(predict.glm(fit1,newdata = x.test, type = 'response') > 0.5, 1,0)
predictedClass <- ifelse(predict.glm(fit1,newdata = x.test, type = 'response') > 0.5, 1,0)
test.y <- ifelse(test.models$TARGET_FLAG2 == "No",0,1)
table(predictedClass,test.y)
rocCurve.fit1 <- roc(response = test.y, predictor = predictedClass)
plot(rocCurve.fit1, legacy.axes = T)
pROC::auc(rocCurve.fit1)
pROC::auc(rocCurve.fit1)
plot(rocCurve.fit1, legacy.axes = T)
PotentialPred
summary(fit1)
