AUC <- c(auc.test.logis,auc.test.logis.rev,round(pROC::auc(rocCurve.dt.test.logis),2)),
KS <- c(ks.test.logis,ks.test.logis.rev,ks.dt.test.logis),
AIC <- c(AIC(train.logistic.full),AIC(train.logistic.rev),AIC(logistic.dt.train)),
Accuracy <-c(confusionMatrix.test.logis$overall[1],confusionMatrix.test.logis.rev$overall[1],confusionMatrix.dt.test$overall[1]))
reportingtable <- data.frame(Section <- c("4.1","4.2","4.3"),
eta <-c(getequation("TARGET_FLAG",train.logistic.full,4),getequation("TARGET_FLAG",train.logistic.rev,4),getequation("TARGET_FLAG",logistic.dt.train,4)),
AUC <- c(auc.test.logis,auc.test.logis.rev,round(pROC::auc(rocCurve.dt.test.logis),2)),
KS <- c(ks.test.logis,ks.test.logis.rev,ks.dt.test.logis),
AIC <- c(AIC(train.logistic.full),AIC(train.logistic.rev),AIC(logistic.dt.train)),
Accuracy <-c(confusionMatrix.test.logis$overall[1],confusionMatrix.test.logis.rev$overall[1],confusionMatrix.dt.test$overall[1]))
logistic.dt.train
PotentialPred <- rownames(tr.bagged$importance)[order(tr.bagged$importance,decreasing = T)][1:12]
PotentialPred <- c(PotentialPred[grep("JOB",PotentialPred)*-1],colnames(df.rev.cleaned)[grep("_Bucket", colnames(df.rev.cleaned))],colnames(df.rev.cleaned)[grep("JOB.c",colnames(df.rev.cleaned))])[c(-3,-6)]
set.seed(10)
trainRows.models <- caret::createDataPartition(df.rev.cleaned$TARGET_FLAG,p = 0.75, list = F)
training.dt <- df.rev.cleaned[trainRows.models,c(PotentialPred,"TARGET_FLAG")]
test.dt <- df.rev.cleaned[-trainRows.models,c(PotentialPred,"TARGET_FLAG")]
logistic.dt.train <- glm(TARGET_FLAG ~ ., family = binomial,data = training.dt)
summary(logistic.dt.train)
paste("Goodness of fit test p Value :", 1- pchisq(logistic.dt.train$null.deviance - deviance(logistic.dt.train),12))
# predict probabilities
logistic.dt.test <- predict(object = logistic.dt.train, newdata = test.dt,type = 'response')
# ROC curves
rocCurve.dt.train.logis <- pROC::roc(response = training.dt[complete.cases(training.dt),"TARGET_FLAG"], predictor = logistic.dt.train$fitted.values)
rocCurve.dt.test.logis <- pROC::roc(response = test.dt$TARGET_FLAG, predictor = logistic.dt.test)
ks.dt.test.logis <- round(ks.test(logistic.dt.test,test.dt$TARGET_FLAG)$statistic,2)
ks.dt.train.logis <- round(ks.test(logistic.dt.train$fitted.values,training.dt[complete.cases(training.dt),"TARGET_FLAG"])$statistic,2)
plot(rocCurve.dt.train.logis,asp = NA, legacy.axes = T,col = "blue")
plot(rocCurve.dt.test.logis, asp = NA, legacy.axes = T, col = "red", add = T)
text(0.2,0.6,paste("Training AUC:",round(pROC::auc(rocCurve.dt.train.logis),2), "KS:",ks.dt.train.logis),cex = 0.7)
text(0.2,0.5,paste("Test AUC:",round(pROC::auc(rocCurve.dt.test.logis),2),"KS:",ks.dt.test.logis),cex = 0.7)
legend("bottomright",lty = 1, legend = c("Train", "Test"), col = c("Blue","Red"))
title("ROC Logistic regression - predictors chosen from decison trees", cex = 0.8)
predicted.train.dt.logis.class <- ifelse(logistic.dt.train$fitted.values >= 0.5,1,0)
confusionMatrix.dt.train <- caret::confusionMatrix(data = predicted.train.dt.logis.class,training.dt[complete.cases(training.dt),"TARGET_FLAG"], positive = "1")
confusionMatrix.dt.train$table
knitr::kable(confusionMatrix.dt.train$overall, caption = "Confusion matrix stats Training set")
predicted.test.dt.logis.class <- ifelse(logistic.dt.test >= 0.5,1,0)
confusionMatrix.dt.test <- caret::confusionMatrix(data = predicted.test.dt.logis.class,test.dt$TARGET_FLAG, positive = "1")
confusionMatrix.dt.test$table
knitr::kable(confusionMatrix.dt.test$overall, caption = "Confusion matrix statsTest set")
reportingtable <- data.frame(Section <- c("4.1","4.2","4.3"),
eta <-c(getequation("TARGET_FLAG",train.logistic.full,4),getequation("TARGET_FLAG",train.logistic.rev,4),getequation("TARGET_FLAG",logistic.dt.train,4)),
AUC <- c(auc.test.logis,auc.test.logis.rev,round(pROC::auc(rocCurve.dt.test.logis),2)),
KS <- c(ks.test.logis,ks.test.logis.rev,ks.dt.test.logis),
AIC <- c(AIC(train.logistic.full),AIC(train.logistic.rev),AIC(logistic.dt.train)),
Accuracy <-c(confusionMatrix.test.logis$overall[1],confusionMatrix.test.logis.rev$overall[1],confusionMatrix.dt.test$overall[1]))
pander::pandoc.table(reportingtable)
confusionMatrix.test.logis$overall[1]
class(confusionMatrix.test.logis$overall[1])
reportingtable <- data.frame(Section = c("4.1","4.2","4.3"),
eta = c(getequation("TARGET_FLAG",train.logistic.full,4),getequation("TARGET_FLAG",train.logistic.rev,4),getequation("TARGET_FLAG",logistic.dt.train,4)),
AUC = c(auc.test.logis,auc.test.logis.rev,round(pROC::auc(rocCurve.dt.test.logis),2)),
KS = c(ks.test.logis,ks.test.logis.rev,ks.dt.test.logis),
AIC = c(AIC(train.logistic.full),AIC(train.logistic.rev),AIC(logistic.dt.train)),
Accuracy = c(confusionMatrix.test.logis$overall[1],confusionMatrix.test.logis.rev$overall[1],confusionMatrix.dt.test$overall[1]))
pander::pandoc.table(reportingtable)
reportingtable <- data.frame(Section = c("4.1","4.2","4.3"),
eta = c(getequation("TARGET_FLAG",train.logistic.full,4),getequation("TARGET_FLAG",train.logistic.rev,4),getequation("TARGET_FLAG",logistic.dt.train,4)),
AUC = c(auc.test.logis,auc.test.logis.rev,round(pROC::auc(rocCurve.dt.test.logis),2)),
KS = c(ks.test.logis,ks.test.logis.rev,ks.dt.test.logis),
AIC = c(AIC(train.logistic.full),AIC(train.logistic.rev),AIC(logistic.dt.train)),
Accuracy = c(confusionMatrix.test.logis$overall[1],confusionMatrix.test.logis.rev$overall[1],confusionMatrix.dt.test$overall[1]),
Chosen = c("No", "Yes", "No"),
Comments = c("Too many predictors needed", "Relatively less for the same performance", "Relatively less accuracy"))
pander::pandoc.table(reportingtable)
df.rev.cleaned.payout <- df.rev.cleaned %>%
filter(TARGET_FLAG > 0)
df.complete <- df.rev.cleaned.payout[complete.cases(df.rev.cleaned.payout),]
cordata <- cor(df.complete)
numericcols <- sapply(df.complete, is.numeric)
numericcols
cordata <- df.complete[,numericcols]
correlations <- cor(cordata)
corrplot::corrplot(correlations)
corrplot::corrplot(correlations,tl.cex = 0.4)
df.rev.cleaned.payout <- df.rev.cleaned %>%
filter(TARGET_FLAG > 0)
df.complete <- df.rev.cleaned.payout[complete.cases(df.rev.cleaned.payout),]
numericcols <- sapply(df.complete, is.numeric)
cordata <- df.complete[,c(numericcols)]
cordata <- cordata[,grep("_Missing",colnames(cordata)*-1)]
grep("_Missing",colnames(cordata)
grep("_Missing",colnames(cordata)
grep("_Missing",colnames(cordata))
grep("_Missing",colnames(cordata))*-1
df.rev.cleaned.payout <- df.rev.cleaned %>%
filter(TARGET_FLAG > 0)
df.complete <- df.rev.cleaned.payout[complete.cases(df.rev.cleaned.payout),]
numericcols <- sapply(df.complete, is.numeric)
cordata <- df.complete[,c(numericcols)]
cordata <- cordata[,grep("_Missing",colnames(cordata))*-1]
correlations <- cor(cordata)
corrplot::corrplot(correlations,tl.cex = 0.4)
df.rev.cleaned.payout <- df.rev.cleaned %>%
mutate(TARGET_AMT = df$TARGET_AMT) %>%
filter(TARGET_FLAG > 0)
df.complete <- df.rev.cleaned.payout[complete.cases(df.rev.cleaned.payout),]
numericcols <- sapply(df.complete, is.numeric)
cordata <- df.complete[,c(numericcols)]
cordata <- cordata[,grep("_Missing",colnames(cordata))*-1]
correlations <- cor(cordata)
corrplot::corrplot(correlations,tl.cex = 0.4)
lm.full <- lm(TARGET_AMT ~ CAR_AGE + BLUEBOOK, data = df.rev.cleaned.payout)
plot(lm.full)
source('~/Documents/MSPA/PREDICT 411/RegressionGLM/getequation.R')
knitr::opts_chunk$set(echo = F, warning = F, message = F,tidy = T )
source('getequation.R')
df.rev.cleaned.payout <- df.rev.cleaned %>%
mutate(TARGET_AMT = df$TARGET_AMT) %>%
filter(TARGET_FLAG > 0)
# df.complete <- df.rev.cleaned.payout[complete.cases(df.rev.cleaned.payout),]
# numericcols <- sapply(df.complete, is.numeric)
# cordata <- df.complete[,c(numericcols)]
# cordata <- cordata[,grep("_Missing",colnames(cordata))*-1]
# correlations <- cor(cordata)
# corrplot::corrplot(correlations,tl.cex = 0.4)
lm.simple <- lm(TARGET_AMT ~ CAR_AGE + BLUEBOOK, data = df.rev.cleaned.payout)
r getequation("TARGET_AMT",lm.simple,2)
getequation("TARGET_AMT",lm.simple,2)
predictionfile <- read.csv(file = 'logit_insurance_test.csv')
View(predictionfile)
predictionfile <- predictionfile %>% select(c(-2,-2))
predictionfile <- read.csv(file = 'logit_insurance_test.csv')
predictionfile <- predictionfile %>% select(c(-2,-3))
library("dplyr")
predictionfile <- read.csv(file = 'logit_insurance_test.csv')
# remove TARGET_FLAG and TARGET_AMT
predictionfile <- predictionfile %>% select(c(-2,-3))
# impute data
df.imp <- VIM::kNN(predictionfile)
# indicator variables created
factorcols <- sapply(df.imp,is.factor)
dummyvars <- dummy::dummy(df.imp[,factorcols],int = T)
df.imp<- cbind(df.imp,dummyvars) %>%
dplyr::mutate(JOB.category = ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
View(df.imp)
pander::pandoc.table(reportingtable)
P_TARGET_FLAG <- predict(train.logistic.rev,newdata = df.imp, type = 'response')
plot(P_TARGET_FLAG)
p.eqn <- getequation("P_TARGET_FLAG",train.logistic.rev,6)
p.eqn
test_p <- df.imp %>%
mutate(P_TARGET_FLAG = -1.259624 - 3.1e-05 * BLUEBOOK  + 2.167618 *  URBANICITY_Highly.Urban..Urban  + 0.702162 *  CAR_USE_Commercial  + 0.347951 *  KIDSDRIV  + 0.015133 *  TRAVTIME  + 0.123052 *  MVR_PTS  - 0.034292 *  CAR_AGE  - 0.817843 *  REVOKED_No  - 0.589647 *  PARENT1_No  - 2e-06 *  HOME_VAL  - 0.05017 *  TIF  + 0.182037 *  CLM_FREQ  - 0.824964 *  CAR_TYPE_Minivan  - 0.235501 *  MSTATUS_Yes  - 0.40715 *  JOB_.  - 0.97424 *  JOB_Manager)
library("dplyr")
predictionfile <- read.csv(file = 'logit_insurance_test.csv')
# remove TARGET_FLAG and TARGET_AMT
predictionfile <- predictionfile %>% select(c(-2,-3))
# impute data
df.imp <- VIM::kNN(predictionfile)
# indicator variables created
factorcols <- sapply(df.imp,is.factor)
dummyvars <- dummy::dummy(df.imp[,factorcols],int = T)
df.imp<- cbind(df.imp,dummyvars) %>%
dplyr::mutate(JOB.category = ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
# Score model
P_TARGET_FLAG <- predict(train.logistic.rev,newdata = df.imp, type = 'response')
p.eqn <- getequation("P_TARGET_FLAG",train.logistic.rev,6)
test_p <- df.imp %>%
mutate(L_TARGET_FLAG = -1.259624 - 3.1e-05 * BLUEBOOK  + 2.167618 *  URBANICITY_Highly.Urban..Urban  + 0.702162 *  CAR_USE_Commercial  + 0.347951 *  KIDSDRIV  + 0.015133 *  TRAVTIME  + 0.123052 *  MVR_PTS  - 0.034292 *  CAR_AGE  - 0.817843 *  REVOKED_No  - 0.589647 *  PARENT1_No  - 2e-06 *  HOME_VAL  - 0.05017 *  TIF  + 0.182037 *  CLM_FREQ  - 0.824964 *  CAR_TYPE_Minivan  - 0.235501 *  MSTATUS_Yes  - 0.40715 *  JOB_.  - 0.97424 *  JOB_Manager) %>%
mutate(P_TARGET_FLAG = (1+exp(-1*L_TARGET_FLAG))^-1)
library("dplyr")
predictionfile <- read.csv(file = 'logit_insurance_test.csv')
# remove TARGET_FLAG and TARGET_AMT
predictionfile <- predictionfile %>% select(c(-2,-3))
# impute data
df.imp <- VIM::kNN(predictionfile)
# indicator variables created
factorcols <- sapply(df.imp,is.factor)
dummyvars <- dummy::dummy(df.imp[,factorcols],int = T)
df.imp<- cbind(df.imp,dummyvars) %>%
dplyr::mutate(JOB.category = ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
# Score model
P_TARGET_FLAG <- predict(train.logistic.rev,newdata = df.imp, type = 'response')
p.eqn <- getequation("P_TARGET_FLAG",train.logistic.rev,6)
test_p <- df.imp %>%
mutate(L_TARGET_FLAG = -1.259624 - 3.1e-05 * BLUEBOOK  + 2.167618 *  URBANICITY_Highly.Urban..Urban  + 0.702162 *  CAR_USE_Commercial  + 0.347951 *  KIDSDRIV  + 0.015133 *  TRAVTIME  + 0.123052 *  MVR_PTS  - 0.034292 *  CAR_AGE  - 0.817843 *  REVOKED_No  - 0.589647 *  PARENT1_No  - 2e-06 *  HOME_VAL  - 0.05017 *  TIF  + 0.182037 *  CLM_FREQ  - 0.824964 *  CAR_TYPE_Minivan  - 0.235501 *  MSTATUS_Yes  - 0.40715 *  JOB_.  - 0.97424 *  JOB_Manager) %>%
mutate(P_TARGET_FLAG = (1+exp(-1*L_TARGET_FLAG))^-1)
library("dplyr")
predictionfile <- read.csv(file = 'logit_insurance_test.csv')
# remove TARGET_FLAG and TARGET_AMT
predictionfile <- predictionfile %>% select(c(-2,-3))
# impute data
df.imp <- VIM::kNN(predictionfile)
# indicator variables created
factorcols <- sapply(df.imp,is.factor)
dummyvars <- dummy::dummy(df.imp[,factorcols],int = T)
df.imp<- cbind(df.imp,dummyvars) %>%
dplyr::mutate(JOB.category = ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
# Score model
P_TARGET_FLAG <- predict(train.logistic.rev,newdata = df.imp, type = 'response')
p.eqn <- getequation("P_TARGET_FLAG",train.logistic.rev,6)
test_p <- df.imp %>%
mutate(L_TARGET_FLAG = -1.259624 - 3.1e-05 * BLUEBOOK  + 2.167618 *  URBANICITY_Highly.Urban..Urban  + 0.702162 *  CAR_USE_Commercial  + 0.347951 *  KIDSDRIV  + 0.015133 *  TRAVTIME  + 0.123052 *  MVR_PTS  - 0.034292 *  CAR_AGE  - 0.817843 *  REVOKED_No  - 0.589647 *  PARENT1_No  - 2e-06 *  HOME_VAL  - 0.05017 *  TIF  + 0.182037 *  CLM_FREQ  - 0.824964 *  CAR_TYPE_Minivan  - 0.235501 *  MSTATUS_Yes  - 0.40715 *  JOB_.  - 0.97424 *  JOB_Manager) %>%
mutate(P_TARGET_FLAG = (1+exp(-1*L_TARGET_FLAG))^-1)
plot(P_TARGET_FLAG)
plot(test_p$P_TARGET_FLAG)
p.eqn <- getequation("P_TARGET_FLAG",train.logistic.rev,8)
p.eqn
library("dplyr")
predictionfile <- read.csv(file = 'logit_insurance_test.csv')
# remove TARGET_FLAG and TARGET_AMT
predictionfile <- predictionfile %>% select(c(-2,-3))
# impute data
df.imp <- VIM::kNN(predictionfile)
# indicator variables created
factorcols <- sapply(df.imp,is.factor)
dummyvars <- dummy::dummy(df.imp[,factorcols],int = T)
df.imp<- cbind(df.imp,dummyvars) %>%
dplyr::mutate(JOB.category = ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
# Score model
P_TARGET_FLAG <- predict(train.logistic.rev,newdata = df.imp, type = 'response')
p.eqn <- getequation("P_TARGET_FLAG",train.logistic.rev,8)
test_p <- df.imp %>%
mutate(L_TARGET_FLAG = -1.25962419 - 3.12e-05 * BLUEBOOK  + 2.16761818 *  URBANICITY_Highly.Urban..Urban  + 0.70216247 *  CAR_USE_Commercial  + 0.34795086 *  KIDSDRIV  + 0.01513301 *  TRAVTIME  + 0.12305204 *  MVR_PTS  - 0.03429193 *  CAR_AGE  - 0.81784286 *  REVOKED_No  - 0.58964657 *  PARENT1_No  - 1.9e-06 *  HOME_VAL  - 0.05017022 *  TIF  + 0.18203741 *  CLM_FREQ  - 0.82496441 *  CAR_TYPE_Minivan  - 0.23550083 *  MSTATUS_Yes  - 0.40715006 *  JOB_.  - 0.97424013 *  JOB_Manager) %>%
mutate(P_TARGET_FLAG = (1+exp(-1*L_TARGET_FLAG))^-1)
plot(P_TARGET_FLAG)
plot(test_p$P_TARGET_FLAG)
library("dplyr")
predictionfile <- read.csv(file = 'logit_insurance_test.csv')
# remove TARGET_FLAG and TARGET_AMT
predictionfile <- predictionfile %>% select(c(-2,-3))
# impute data
df.imp <- VIM::kNN(predictionfile)
# indicator variables created
factorcols <- sapply(df.imp,is.factor)
dummyvars <- dummy::dummy(df.imp[,factorcols],int = T)
df.imp<- cbind(df.imp,dummyvars) %>%
dplyr::mutate(JOB.category = ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
# Score model
#P_TARGET_FLAG <- predict(train.logistic.rev,newdata = df.imp, type = 'response') - Use this in the source file to check
# p.eqn <- getequation("P_TARGET_FLAG",train.logistic.rev,8) - Use this to get the eta equation correctly...available in the source
#
test_p <- df.imp %>%
mutate(L_TARGET_FLAG = -1.25962419 - 3.12e-05 * BLUEBOOK  + 2.16761818 *  URBANICITY_Highly.Urban..Urban  + 0.70216247 *  CAR_USE_Commercial  + 0.34795086 *  KIDSDRIV  + 0.01513301 *  TRAVTIME  + 0.12305204 *  MVR_PTS  - 0.03429193 *  CAR_AGE  - 0.81784286 *  REVOKED_No  - 0.58964657 *  PARENT1_No  - 1.9e-06 *  HOME_VAL  - 0.05017022 *  TIF  + 0.18203741 *  CLM_FREQ  - 0.82496441 *  CAR_TYPE_Minivan  - 0.23550083 *  MSTATUS_Yes  - 0.40715006 *  JOB_.  - 0.97424013 *  JOB_Manager) %>%
mutate(P_TARGET_FLAG = (1+exp(-1*L_TARGET_FLAG))^-1) %>%
mutate(TARGET_AMT = ifelse(P_TARGET_FLAG < 0.5, 0, 4434.04 - 52.11 * CAR_AGE  + 0.12 *  BLUEBOOK))
library("dplyr")
predictionfile <- read.csv(file = 'logit_insurance_test.csv')
# remove TARGET_FLAG and TARGET_AMT
predictionfile <- predictionfile %>% select(c(-2,-3))
# impute data
df.imp <- VIM::kNN(predictionfile)
# indicator variables created
factorcols <- sapply(df.imp,is.factor)
dummyvars <- dummy::dummy(df.imp[,factorcols],int = T)
df.imp<- cbind(df.imp,dummyvars) %>%
dplyr::mutate(JOB.category = ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
# Score model
#P_TARGET_FLAG <- predict(train.logistic.rev,newdata = df.imp, type = 'response') - Use this in the source file to check
# p.eqn <- getequation("P_TARGET_FLAG",train.logistic.rev,8) - Use this to get the eta equation correctly...available in the source
#
test_p <- df.imp %>%
mutate(L_TARGET_FLAG = -1.25962419 - 3.12e-05 * BLUEBOOK  + 2.16761818 *  URBANICITY_Highly.Urban..Urban  + 0.70216247 *  CAR_USE_Commercial  + 0.34795086 *  KIDSDRIV  + 0.01513301 *  TRAVTIME  + 0.12305204 *  MVR_PTS  - 0.03429193 *  CAR_AGE  - 0.81784286 *  REVOKED_No  - 0.58964657 *  PARENT1_No  - 1.9e-06 *  HOME_VAL  - 0.05017022 *  TIF  + 0.18203741 *  CLM_FREQ  - 0.82496441 *  CAR_TYPE_Minivan  - 0.23550083 *  MSTATUS_Yes  - 0.40715006 *  JOB_.  - 0.97424013 *  JOB_Manager) %>%
mutate(P_TARGET_FLAG = (1+exp(-1*L_TARGET_FLAG))^-1) %>%
mutate(TARGET_AMT = ifelse(P_TARGET_FLAG < 0.5, 0, 4434.04 - 52.11 * CAR_AGE  + 0.12 *  BLUEBOOK)) %>%
mutate(CRASH = ifelse(P_TARGET_FLAG < 0.5, 0, 1))
# check results ... simple plots
#ggplot(data = test_p, mapping = aes(x = ))
ggplot(data = test_p, mapping = aes(x = CRASH, y = TARGET_AMT )) + geom_point()
ggplot(data = test_p, mapping = aes(x = CRASH, y = TARGET_AMT )) + geom_point()
library("dplyr")
predictionfile <- read.csv(file = 'logit_insurance_test.csv')
# remove TARGET_FLAG and TARGET_AMT
predictionfile <- predictionfile %>% select(c(-2,-3))
# impute data
df.imp <- VIM::kNN(predictionfile)
# indicator variables created
factorcols <- sapply(df.imp,is.factor)
dummyvars <- dummy::dummy(df.imp[,factorcols],int = T)
df.imp<- cbind(df.imp,dummyvars) %>%
dplyr::mutate(JOB.category = ifelse(JOB %in% c("Student", "Home Maker", "Clerical", "z_Blue_Collar"),0,1))
# Score model
#P_TARGET_FLAG <- predict(train.logistic.rev,newdata = df.imp, type = 'response') - Use this in the source file to check
# p.eqn <- getequation("P_TARGET_FLAG",train.logistic.rev,8) - Use this to get the eta equation correctly...available in the source
#
test_p <- df.imp %>%
mutate(L_TARGET_FLAG = -1.25962419 - 3.12e-05 * BLUEBOOK  + 2.16761818 *  URBANICITY_Highly.Urban..Urban  + 0.70216247 *  CAR_USE_Commercial  + 0.34795086 *  KIDSDRIV  + 0.01513301 *  TRAVTIME  + 0.12305204 *  MVR_PTS  - 0.03429193 *  CAR_AGE  - 0.81784286 *  REVOKED_No  - 0.58964657 *  PARENT1_No  - 1.9e-06 *  HOME_VAL  - 0.05017022 *  TIF  + 0.18203741 *  CLM_FREQ  - 0.82496441 *  CAR_TYPE_Minivan  - 0.23550083 *  MSTATUS_Yes  - 0.40715006 *  JOB_.  - 0.97424013 *  JOB_Manager) %>%
mutate(P_TARGET_FLAG = (1+exp(-1*L_TARGET_FLAG))^-1) %>%
mutate(TARGET_AMT = ifelse(P_TARGET_FLAG < 0.5, 0, 4434.04 - 52.11 * CAR_AGE  + 0.12 *  BLUEBOOK)) %>%
mutate(CRASH = ifelse(P_TARGET_FLAG < 0.5, 0, 1)) %>%
select(INDEX,P_TARGET_FLAG,TARGET_AMT)
# check results ... simple plots
write.csv(test_p,'SESHADRI.logit_insurance_test.csv')
male_Yes <- 10
male_no <- 30
male_total <- male_Yes + male_no
female_Yes <- 6
female_no <- 34
female_total <- female_Yes + female_no
prob_male_use <- male_Yes/male_total
prob_female_use <- female_Yes/female_total
odds_male_use <- prob_male_use/(1-prob_male_use)
odds_male_use
knitr::opts_chunk$set(echo = TRUE)
odds_Female_use <- 6/34
odds_Female_use
odds_female_use <- prob_female_use/(1 - prob_female_use)
odds_female_use
2/(38/58)
OR.Male.to.Female <- odds_Male_use/odds_female_use
# Data
Male_Yes <- 10
Male_No <- 30
Female_Yes <- 6
Female_No <- 34
# Odds among male and females
odds_Male_use <- 10/30
odds_Female_use <- 6/34
# odds ratio Male vs Female
OR.Male.to.Female <- odds_Male_use/odds_female_use
OR.Male.to.Female
odds_ratio <- odds_male_use/odds_female_use
odds_ratio
p.male.use <- Male_Yes/(Male_Yes + Male_No)
p.female.use <- Female_Yes/(Female_Yes + Female_No)
p.male.use
p.female.use
prob_male_use
prob_female_use
# Data
Male_Yes <- 10
Male_No <- 30
Female_Yes <- 6
Female_No <- 34
# Probabilities of use among male and females
p.male.use <- Male_Yes/(Male_Yes + Male_No)
p.female.use <- Female_Yes/(Female_Yes + Female_No)
# Odds among male and females
odds_Male_use <- Male_Yes/Male_No
odds_Female_use <- Female_Yes/Female_No
# odds ratio Male vs Female
OR.Male.to.Female <- odds_Male_use/odds_female_use
Q1df <- data.frame(Prob.Male.use = p.male.use, Prob.Female.use = p.female.use, Odd.Male.use = odds_Male_use, Odds.Female.use = odds_Female_use, `OddsRatio m/f` = OR.Male.to.Female)
knitr::kable(Q1df)
# Data
Male_Yes <- 10
Male_No <- 30
Female_Yes <- 6
Female_No <- 34
# Probabilities of use among male and females
p.male.use <- Male_Yes/(Male_Yes + Male_No)
p.female.use <- Female_Yes/(Female_Yes + Female_No)
# Odds among male and females
odds_Male_use <- Male_Yes/Male_No
odds_Female_use <- Female_Yes/Female_No
# odds ratio Male vs Female
OR.Male.to.Female <- odds_Male_use/odds_female_use
Q1df <- data.frame(Prob.Male.use = p.male.use, Prob.Female.use = p.female.use, Odd.Male.use = odds_Male_use, Odds.Female.use = odds_Female_use, `OddsRatio m/f` = OR.Male.to.Female)
knitr::kable(round(Q1df,2))
religion <- read.csv(file = 'religion.csv')
View(religion)
sanitycheck <- do.call(rbind,dfapply(df,favstats, select = is.numeric))
sanitycheck <- do.call(rbind,dfapply(religion,favstats, select = is.numeric))
knitr::kable(round(sanitycheck,2), caption = "Summary statistics")
religion <- read.csv(file = 'religion.csv')
sanitycheck <- do.call(rbind,dfapply(religion,favstats, select = is.numeric))
#knitr::kable(round(sanitycheck,2), caption = "Summary statistics")
# note there is missing data
attending.respondents <- sum(religion$RELSCHOL)
Total.respondents <- nrow(religion)
odds_relschol <- attending.respondents/(Total.respondents - attending.respondents)
odds_relschol
sum(religion$RELSCHOL)
nrow(religion)
prob_attend <- sum(religion$RELSCHOL)/nrow(religion)
odds_attend <- prob_attend/(1 - prob_attend)
odds_attend
prob_relschol <- attending.respondents/(Total.respondents)
prob_relschol
prob_attend
table(religion$RELSCHOL,religion$RACE)
install.packages("descr")
descr::CrossTable(religion$RELSCHOL,religion$RACE)
descr::CrossTable(religion$RELSCHOL,religion$RACE,prop.r = F,prop.c = F,prop.chisq = F)
descr::CrossTable(religion$RELSCHOL,religion$RACE,prop.r = F,prop.c = F,prop.chisq = F,prop.t = F)
ct <- descr::CrossTable(religion$RELSCHOL,religion$RACE,prop.r = F,prop.c = F,prop.chisq = F,prop.t = F)
ct
as.data.frame(ct)
ct
table(religion$RELSCHOL,religion$RACE)
Prob.nonwhite.relschool.attend <- crosstable[2,1]/sum(crosstable[,1])
crosstable <- table(religion$RELSCHOL,religion$RACE)
Prob.nonwhite.relschool.attend <- crosstable[2,1]/sum(crosstable[,1])
Prob.white.relschool.attend <- crosstable[2,2] / sum(crosstable[,2])
Prob.nonwhite.relschool.attend
Prob.white.relschool.attend
non_white_no <- 76
non_white_Yes <- 26
non_white_total <- non_white_no + non_white_Yes
white_no <- 470
white_Yes <- 54
white_total <- white_no + white_Yes
prob_non_white <- non_white_Yes/non_white_total
prob_white <- white_Yes/white_total
prob_non_white
Prob.nonwhite.relschool.attend
Prob.white.relschool.attend
prob_white
crosstable
ct
religion <- read.csv(file = 'religion.csv')
sanitycheck <- do.call(rbind,dfapply(religion,favstats, select = is.numeric))
#knitr::kable(round(sanitycheck,2), caption = "Summary statistics")
# note there is missing data
attending.respondents <- sum(religion$RELSCHOL)
Total.respondents <- nrow(religion)
odds_relschol <- attending.respondents/(Total.respondents - attending.respondents)
prob_relschol <- attending.respondents/(Total.respondents)
ct <- descr::CrossTable(religion$RELSCHOL,religion$RACE,prop.r = F,prop.c = F,prop.chisq = F,prop.t = F)
ct
crosstable <- table(religion$RELSCHOL,religion$RACE)
Prob.nonwhite.relschool.attend <- crosstable[2,1]/sum(crosstable[,1])
Prob.white.relschool.attend <- crosstable[2,2] / sum(crosstable[,2])
odds.nonwhite.relschool.attend <- crosstable[2,1]/crosstable[1,1]
odds.white.relschool.attend <- crosstable[2,2]/crosstable[1,2]
OR <- odds.white.relschool.attend/odds.nonwhite.relschool.attend
odds.nonwhite.relschool.attend
odd_non_white <- prob_non_white/ (1 - prob_non_white)
odd_non_white
odd_white <- prob_white/ (1 - prob_white)
odd_white
odds_ratio_2.b <- odd_white/odd_non_white
odds_ratio_2.b
odds.white.relschool.attend <- crosstable[2,2]/crosstable[1,2]
OR <- odds.white.relschool.attend/odds.nonwhite.relschool.attend
OR
model1 <- glm(RELSCHOL ~ RACE, family = binomial,data = religion)
model1 <- glm(RELSCHOL ~ RACE, family = binomial,data = religion)
model2 <- glm(RELSCHOL ~ RACE + ATTEND + INCOME, family = binomial,data = religion)
summary(model1)
coef1 <- summay(model1)$coefficients
coef1 <- summary(model1)$coefficients
coef1
coef1 <- coefficients(model1)
coef1
coef1 <- coefficients(model1)[2]
coef1
exp(coef1)
q3bdf <- data.frame(Model = c(1,2),AIC = c(AIC_model1,AIC_model2), BIC = c(BIC_model1,BIC_model2))
model1 <- glm(RELSCHOL ~ RACE, family = binomial,data = religion)
model2 <- glm(RELSCHOL ~ RACE + ATTEND + INCOME, family = binomial,data = religion)
summary(model1)
coef1 <- coefficients(model1)[2]
odds.ratio <- exp(coef1)
AIC_model1 <- AIC(model1)
BIC_model1 <- BIC(model1)
AIC_model2 <- AIC(model2)
BIC_model2 <- BIC(model2)
q3bdf <- data.frame(Model = c(1,2),AIC = c(AIC_model1,AIC_model2), BIC = c(BIC_model1,BIC_model2))
knitr::kable(q3df)
q3bdf <- data.frame(Model = c(1,2),AIC = c(AIC_model1,AIC_model2), BIC = c(BIC_model1,BIC_model2))
q3bdf
odds_relschol
prob_relschol
length(odds_relschol)
odds_relschol
odds_relschol
prob_relschol
odds_relschol
source("getequation.R")
eqn <- getequation("RELSCHOL",model2)
eqn
RACE <- c(1,0)
ATTEND <- c(5,5)
INCOME <- c(4,4)
logoddsRELSHOL <- -3.58 - 1.29 * RACE  + 0.33 *  ATTEND  + 0.2 *  INCOME
odds_RELSCHOL <- exp(logoddsRELSHOL)
odds_RELSCHOL
paste("The odds of attendance for white and non white are ", odds_RELSCHOL, "respectively")
paste("The odds of attendance for white and non white are ", odds_RELSCHOL[1], "and",odds_RELSCHOL[2], "respectively")
paste("The odds of attendance for white and non white are ", round(odds_RELSCHOL[1],2), "and",round(odds_RELSCHOL[2],2), "respectively")
summary(model1)
summary(model2)
summary(model1)
summary(model2)
coefficients(model2)
adj.odds.Ratio <- exp(coefficients(model2)[2])
adj.odds.Ratio
names(adj.odds.Ratio) <- NULL
adj.odds.Ratio
summary(model2)
adj.odds.Ratio
knitr::opts_chunk$set(echo = TRUE,tidy = T, out.width = 60)
model1.probit <- glm(RELSCHOL ~ RACE, family = binomial(link = 'probit'),data = religion)
model2.probit <- glm(RELSCHOL ~ RACE + ATTEND + INCOME, family = binomial(link = 'probit'),data = religion)
model1.probit$fitted.values
summary(model1.probit)
pnorm(-0.6591)
pRob.White.attendance <- pnorm(sum(coefficients(model1.probit)))
model1.probit
summary(model1.probit)
prob.NonWhite.attendance <- pnorm(coefficients(model1.probit)[1])
AIC_model1.probit <- AIC(model1.probit)
BIC_model1.probit <- BIC(model1.probit)
AIC_model2.probit <- AIC(model2.probit)
BIC_model2.probit <- BIC(model2.probit)
q4bdf <- data.frame(Model = c(1,2),AIC = c(AIC_model1.probit,AIC_model2.probit), BIC = c(BIC_model1.probit,BIC_model2.probit))
AIC_model1.probit <- AIC(model1.probit)
BIC_model1.probit <- BIC(model1.probit)
AIC_model2.probit <- AIC(model2.probit)
BIC_model2.probit <- BIC(model2.probit)
q4bdf <- data.frame(Model = c(1,2),AIC = c(AIC_model1.probit,AIC_model2.probit), BIC = c(BIC_model1.probit,BIC_model2.probit))
knitr::kable(q4bdf, caption = "AIC and BICs for probit")
eqn2 <- getequation(model2.probit)
eqn2 <- getequation("ATTEND",model2.probit)
eqn2
eqn2 <- getequation("ATTEND",model2.probit)
RACE <- c(1,0)
ATTEND <- c(5,5)
INCOME <- c(4,4)
predicted.probs <- pnorm(-2.07 - 0.73 * RACE  + 0.19 *  ATTEND  + 0.12 *  INCOME)
