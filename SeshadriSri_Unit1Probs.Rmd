---
title: "Unit 1 Assignment"
author: "Sri Seshadri"
date: "9/24/2017"
output: 
  pdf_document:
      toc: true
      toc_depth: 2
---
\pagebreak 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = F, message = F)
library(magrittr)
```

## Chapter 1. Question 1

a. Figure 1 shows the sctterplot of GPA vs SAT-Quant. There appears to be a linear relationship between the two variables. However the observations 2 and 5 in the plot appear to be influential points. If the two poitns are removed from the data, the straight line fit would have a steeper slope. Further analysis of the model is in below sections.

```{r fig.cap= 'Scatterplot of GPA vs SAT-Quant', fig.height=3, fig.width=4}
# read data in

GPA <- readr::read_csv(file = 'gpa.csv')
GPA1 <- head(GPA,8)
# GPA1 <- GPA1[c(-2,-5),] # To show that observations 2 and 5 are influential points
library(ggplot2)
ggplot(data = GPA1, mapping = aes(x = SAT_QUAN, y = GPA)) + geom_point() + geom_smooth(method = 'lm',se = F) + theme_classic()

# Model for question b
model1.lm <- lm(data = GPA1, formula = GPA ~ SAT_QUAN)
coefs <- round(coefficients(model1.lm),2)
signs <- ifelse(sign(coefs)==1,"+", "-")
Betas <- paste(abs(coefs[2:length(coefs)]),"*",'SAT_QUANT')
model1eqn <- paste("GPA = ",paste(coefs[1],paste(paste(signs[2:2], Betas),collapse = " ")))
model1data <- broom::augment(model1.lm)
```




b. The GPA is modeled as :

__`r model1eqn`__

   With Intercept as `r coefs[1]` and slope as `r coefs[2]`
   
   
   
c. The Predicted values and the residuals are shown in the table below.

```{r}
df <- model1data[,c('GPA','SAT_QUAN','.fitted','.resid')]
knitr::kable(df,caption = "Predicted values and residuals")
z <- anova(model1.lm)
SSE <- z$`Sum Sq`[2]
```

The R Squared value is found to be `r mosaic::rsquared(model1.lm)` and SSE = `r SSE`

d. Figure 2 shows the residuals plot against the predicted values of GPA. The residuals appear random.


```{r, fig.cap= "Residuals vs predicted GPA",fig.height=3, fig.width=4,fig.align='center'}
ggplot(data = model1data, mapping = aes(x = .fitted, y = .resid)) + geom_point() + geom_smooth(method = 'lm',se = F) + theme_bw()

```


## Chapter 1. Question 2

Figure 3 shows the relationship between quantitative SAT score against GPA for the full data. Observation 2 now doesn't seem as bad as an influential point in the context of the full data.

```{r,fig.cap= 'Scatterplot of GPA vs SAT-Quant - Full data',fig.height=3, fig.width=4}
ggplot(data = GPA, mapping = aes(x = SAT_QUAN, y = GPA)) + geom_point() + geom_smooth(method = 'lm',se = F) + theme_classic()

model2.lm <- lm(data = GPA, formula = GPA ~ SAT_QUAN)
coefs_2 <- round(coefficients(model2.lm),2)
signs_2 <- ifelse(sign(coefs_2)==1,"+", "-")
Betas_2 <- paste(abs(coefs_2[2:length(coefs_2)]),"*",'SAT_QUANT')
model2eqn <- paste("GPA = ",paste(coefs_2[1],paste(paste(signs_2[2:2], Betas_2),collapse = " ")))
model2data <- broom::augment(model2.lm)

```

Below is the summary for the model :

__`r model2eqn`__

```{r}
summary(model2.lm)
anova(model2.lm)
z2 <- anova(model2.lm)
SSE2 <- z2$`Sum Sq`[2]
MSE2 <- SSE2/nrow(model2data)
modelcomparison <- data.frame(Question = c(1,2),model = c(model1eqn, model2eqn), RSquared = c(mosaic::rsquared(model1.lm),mosaic::rsquared(model2.lm)), MSE = c(SSE/nrow(GPA1), MSE2),First_8obs_MSE = c(SSE/nrow(GPA1), sum(model2data$.resid[8]^2)/8) )
```





Figure 4 shows the residual analysis of the model above. The residuals are fairly normally distributed and there is a hint of unequal variance in the residuals. May be we are missing another predictor. The next section will explore additional predictors.

```{r , fig.cap= 'Residuals of model with full data', fig.align='center',fig.height=4}
par(mfrow = c(1,2))
qqnorm(y=model2.lm$residuals)
qqline(y=model2.lm$residuals)
plot(y = model2.lm$residuals,x = model2.lm$model$GPA, xlab = 'GPA', ylab = 'Residuals',main = 'GPA vs Residuals')

```

\pagebreak

### Model comparison

The models in question 1 and 2 are cpmpared in the table below. We see that model for question 1 has a better R Squared value and MSE. However, the second model fits the data in question 1 better with much lower MSE. As mentioned above, the residuals for model 2 appear to have non-constant variance. May be another predictor is required. 

```{r}
pander::pandoc.table(modelcomparison,caption = "Model comparison")
```
\pagebreak 

## Chapter 1 Question 3

a. Figure 5 shows the relationship between GPA and Highschool English scores. There isn't a strong linear relationship.

```{r, fig.cap='GPA vs HighSchool English', fig.height=3, fig.width=4}
model3a <- lm(data = GPA, formula = GPA ~ HS_ENGL)
coefs_3a <- round(coefficients(model3a),2)
signs_3a <- ifelse(sign(coefs_3a)==1,"+", "-")
Betas_3a <- paste(abs(coefs_3a[2:length(coefs_3a)]),"*",'HS_ENGL')
model3aeqn <- paste("GPA = ",paste(coefs_3a[1],paste(paste(signs_3a[2:2], Betas_3a),collapse = " ")))
model3adata <- broom::augment(model3a)

ggplot(data = GPA, mapping = aes(x = HS_ENGL, y = GPA)) + geom_point() + theme_bw() + geom_smooth(method = 'lm',se = F)
```

Below is the summary of the model:

__`r model3aeqn`__

```{r}
summary(model3a)
anova(model3a)
```

### b. Using Highschool english and SAT verbal scores as predictors

It'll be useful to understand the correlations that exist amongst the preditors. To better interpret the model in the context of variability of the regression coefficents (when the predictors are correlated). Figure 6 shows the correalations plot of GPA data. It's seen that the highschool english and verbal SAT scores are not highly correlated.

```{r, fig.cap='Correlation Plot', fig.width=4,fig.height=3}
correlations <- cor(GPA)
corrplot::corrplot(correlations,tl.cex = 1)
```

```{r, fig.cap='Relationship between predictors',fig.height=3, fig.width=4}
p <- ggplot(data = GPA, mapping = aes(x = SAT_VERB, y = GPA)) + geom_point() + geom_smooth(method = 'lm',se = F) + theme_classic()
p2 <- ggplot(data = GPA, mapping = aes(x = SAT_VERB, y = HS_ENGL)) + geom_point() + geom_smooth(method = 'lm',se = F) + theme_classic()
library(gridExtra)
grid.arrange(p,p2, ncol = 2)
```

```{r}
model3b <- lm(GPA~HS_ENGL + SAT_VERB, data = GPA)
Predictors <- c('HS_ENGL','SAT_VERB')
model3bdata <- broom::augment(model3b)
coefs3b <- round(coefficients(model3b),2)
signs3b <- ifelse(sign(coefs3b)==1,"+", "-")
Betas3b <- paste(abs(coefs3b[2:length(coefs3b)]),"*",Predictors)
model3beqn <- paste("GPA = ",paste(coefs3b[1],paste(paste(signs3b[2:length(signs3b)], Betas3b),collapse = " "))) 

```

Below is the summary for the model :

__`r model3beqn`__  

The model has an adjusted R squared of 51%, which is about half of the variation. Not a good explanatory model.The residuals vs actuals have a non-random relationship. The model might be missing a predictor. 

```{r}
summary(model3b)
anova(model3b)

```

\pagebreak

```{r, fig.cap='Residual analysis'}
layout(matrix(c(1,2,3,4),byrow = 2, nrow = 2, ncol = 2))
qqnorm(model3bdata$.resid)
qqline(model3bdata$.resid)
plot(x = model3bdata$GPA, y = model3bdata$.resid, xlab = 'GPA', ylab = 'Residuals')
plot(x = model3bdata$SAT_VERB, y = model3bdata$.resid, xlab = 'GPA', ylab = 'Residuals')
plot(x = model3bdata$HS_ENGL, y = model3bdata$.resid, xlab = 'GPA', ylab = 'Residuals')
# lattice::xyplot(.resid~GPA,data = model3bdata,type =c("p","r"))
# plot.new()
# qqnorm(model3bdata$.resid)
# lattice::xyplot(.resid~HS_ENGL,data = model3bdata,type =c("p","r"))
# lattice::xyplot(.resid~SAT_VERB,data = model3bdata,type =c("p","r"))
# layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))
```


```{r}
model3c <- lm(GPA~HS_ENGL + SAT_VERB + SAT_QUAN, data = GPA)
Predictors <- c('HS_ENGL','SAT_VERB','SAT_QUAN')
model3cdata <- broom::augment(model3c)
coefs3c <- round(coefficients(model3c),2)
signs3c <- ifelse(sign(coefs3c)==1,"+", "-")
Betas3c <- paste(abs(coefs3c[2:length(coefs3c)]),"*",Predictors)
model3ceqn <- paste("GPA = ",paste(coefs3c[1],paste(paste(signs3c[2:length(signs3c)], Betas3c),collapse = " "))) 

```

### c. Below is the summary for the model, with addition of SAT_QUAN as predictor to the above model in 3b.

__`r model3ceqn`__
    
It is seen that the residuals are fairly random and normally distributed. The intercept and HS_ENGL scores from the t -test are statistically insignificant. The SAT scores are key contributors to the model.    
```{r}
summary(model3c)
anova(model3c)

```

```{r,fig.cap = 'Model 3c residual analysis', fig.height=6}

layout(matrix(c(1,1,2,3,4,5),byrow = T, nrow = 3, ncol = 2))
plot(x = model3cdata$.fitted, y = model3cdata$.resid, xlab = 'fitted GPA', ylab = 'Residuals')
qqnorm(y = model3c$residuals)
qqline(model3c$residuals)
plot(x = model3cdata$HS_ENGL, y = model3cdata$.resid, xlab = 'HS_ENGL', ylab = 'Residuals')
plot(x = model3cdata$SAT_VERB, y = model3cdata$.resid, xlab = 'SAT_VERB', ylab = 'Residuals')
plot(x = model3cdata$SAT_QUAN, y = model3cdata$.resid, xlab = 'SAT_QUAN', ylab = 'Residuals')
```

## Chapter 1 Question 4

a. 78% of the Highschool english score contributes to the overall GPA at the end of 1st year of college.
b. 26% of the SAT quantitative score contributes to the overall GPA at the end of 1st year of college.

## Chapter 1 Question 5

The contribution of highschool english score to 1st year college GPA turned out to be negligible after the inclusion of the SAT scores. From test of individual regression coefficients' significance (t-test) in question 3c, it can be seen that the regression coefficient for HS_ENGL is not statistically different from zero. The t-test results is reproduced below:

```{r}

summary(model3c)

```

## Chapter 1 Question 6

a. Figure 9 shows the qqplot of residuals, though the residuals are a bit left leaning/skewed; for practical purposes they seem normal.

b. Figure 9 shows the raw residuals against fitted GPA. The residuals look to have a cyclical pattern. The same plot is reproduced below (Figure 10) with spline. However this may be purely random occurance, more sampling may help to confirm the pattern. The raw residuals can be misleading if there is an influential point that is influencing the regression coefficients to pull the fit closer to itself. Looking at studentized residuals can be helpful; shown in the right panel of figure 10. 

The two plots in figure 10 are not different. This indicates that there aren't influential points. It'll be interesting to look at the Cook's distance.

```{r, fig.cap = 'fitted vs residuals',fig.height=4}
res1 <- ggplot(data = model3cdata, mapping = aes(x = .fitted, y = .resid)) + geom_point() + geom_smooth() + theme_bw()
model3cdata$student.res <- rstudent(model3c)
res2 <- ggplot(data = model3cdata, mapping = aes(x = .fitted, y = student.res)) + geom_point() + geom_smooth() + theme_bw()
grid.arrange(res1,res2,ncol=2)
```

\pagebreak


c.  The distribution of the studentized residuals, leverage and cook's distance is shown below.

    The studentized residuals do not show outliers. The residuals are within +/- 2 standard deviations. Observation 17 has leverage of 0.5 which is greater than 2p/n = 0.4. This shows that this point is outlier in the x space. However the Cook's distance show that there is no effect of beta coefficients. Obervation 17 is more a leverage point and not an influencial point. 
 
 \pagebreak 
 
```{r, fig.cap="Leverage and Influence analysis",fig.height=6}
par(mfrow= c(3,2))
hist(model3cdata$student.res, xlab = "stud.Residuals", main = "")
plot(model3cdata$.hat, ylab = 'Leverage')
hist(model3cdata$.hat,xlab = 'leverage', main = "")
plot(model3c, which=4, cook.levels = 0.1666, main = "")
hist(model3cdata$.cooksd,xlab = "Cook's Distance", main= "")
```

\pagebreak

## Chapter 2 Question 1

a. Poisson distribution
b. Binomial distribution
c. Normal distribution ? 
d. Multinomial
e. Binomial
f. Multinomial
g. negative binomial


## Chapter 2 Question 2

a. Poisson distribution  - Natural logrithm link
b. Binomial distribution  - Logit 
c. Normal distribution    -  Identity
d. Multinomial            -  generalized logit 
e. Binomial               - logit
f. Multinomial            -  generalized logit 
g. negative binomial      - Logit


## Chapter 2 Question 3


```{r}
accidents <- data.frame(Number = 0:7, Frequency = c(121,199,21,12,5,4,2,1))
accidents <- accidents %>% 
              dplyr::mutate(total = Number * Frequency)
mean_accidents <- sum(accidents$total)/sum(accidents$Frequency)
accidents <- accidents %>% 
                dplyr::mutate(SS = (Number - mean_accidents)^2 * Frequency)
Variance <- sum(accidents$SS) / (sum(accidents$Frequency) -1 )
Question <- c('a','b.1','b.2','b.3','b.4','c.1','c.2','d')
What <- c('Alcohol use', 'employed full time','employed part time','unemployed','non-participants','Low-Self Esteem', 'High-Self Esteem', 'Accidents per day')
Expected <- c(1500*0.65,1500*0.65,0.15 * 200,0.10 * 200,0.20 * 200,850*0.45, 850*0.55,round(mean_accidents,2))
Variance <- c(1500*0.65 * (1 - 0.65),0.55 * 200 * (1-0.55),0.15 * 200 * (1-0.15),0.10 * 200 * (1-0.10),0.20 * 200 * (1-0.20),850*0.45*0.55,850*0.45*0.55,round(Variance,2))
response <- data.frame(Question,What, Expected,Variance)
knitr::kable(response)
```

## Chapter 2 Question 4

```{r,echo=T}
p <- 0.4
n <- 30
r <- 12
NBmean <- r/p
NBVar <- r*(1-p)/p^2

p30 <- choose(n-1,r-1)*p^r*(1-p)^(n-r)

```

The computation formula for mean, variance and probability  can be see in the R Code above.

```{r}
df <- data.frame(Mean = NBmean, Variance = NBVar, `Prob of Success by reaching 30` = round(p30,2))
knitr::kable(df)
```

## Chapter 2 Question 5

```{r}
p <- (1:4)/10
probs <- function(p,n = 6, i = 2) {
  dbinom(i,n,p)
}
probabilities <- sapply(p,probs)
df5 <- data.frame(p = p, `probability when i equals 2` = round(probabilities,2))
knitr::kable(df5)
```

p = 0.3 is the most likely value of p

## Chapter 2 Question 6

```{r}
usdata <- read.csv('usdata.csv')
null.lm <- glm(formula = VIOLRATE ~ 1, data = usdata)
DevianceMc <- deviance(null.lm)
ln_LMc <- DevianceMc/-2
summary(null.lm)
anova(null.lm)

model2.6.lm <- glm(formula = VIOLRATE ~ UNEMPRAT + DENSITY + GSPROD, data = usdata)
summary(model2.6.lm)

DevianceMu <- deviance(model2.6.lm)
ln_LMu <- DevianceMu/-2
Rsq_McF <-  1 - (ln_LMu - 4)/ln_LMc

```

